{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection pool created successfully\n",
      "successfully received connection from connection pool \n",
      "Put away a PostgreSQL connection\n"
     ]
    }
   ],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "from firebase_admin import db\n",
    "import pickle\n",
    "import os\n",
    "from psycopg2.pool import ThreadedConnectionPool\n",
    "import psycopg2.extras\n",
    "\n",
    "\n",
    "\n",
    "def setup_firebase():\n",
    "    config = {\n",
    "        \"apiKey\": \"AIzaSyCznO4_adkIorJSXO6wNNPkR7D-HBFEfe0\",\n",
    "        \"authDomain\": \"simpleintervals.firebaseapp.com\",\n",
    "        \"databaseURL\": \"https://simpleintervals.firebaseio.com\",\n",
    "        \"storageBucket\": \"simpleintervals.appspot.com\",\n",
    "        \"serviceAccount\": \"AUTH/SimpleIntervals-f3d1a6f15f68.json\"\n",
    "    }\n",
    "\n",
    "    # Use a service account\n",
    "    cred = credentials.Certificate('AUTH/SimpleIntervals-f3d1a6f15f68.json')\n",
    "    firebase_admin.initialize_app(cred, config)\n",
    "\n",
    "class ProcessSafePoolManager(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.last_seen_process_id = os.getpid()\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        self._init()\n",
    "\n",
    "    def _init(self):\n",
    "        self._pool = ThreadedConnectionPool(*self.args, **self.kwargs)\n",
    "\n",
    "    def getconn(self):\n",
    "        current_pid = os.getpid()\n",
    "        if not (current_pid == self.last_seen_process_id):\n",
    "            self._init()\n",
    "            print(\"New id is \" + current_pid + \", old id was \" + self.last_seen_process_id)\n",
    "            self.last_seen_process_id = current_pid\n",
    "        return self._pool.getconn()\n",
    "\n",
    "    def putconn(self, conn):\n",
    "        return self._pool.putconn(conn)\n",
    "    \n",
    "def setup_postgres():\n",
    "    SQL_PASSWORD = 'yjnc2xRbEENHbmQ'\n",
    "    pool = None\n",
    "    try:\n",
    "        pool = ProcessSafePoolManager(1, 10, \n",
    "                                      host='35.238.139.24',\n",
    "                                      port='5432',\n",
    "                                      user='server',\n",
    "                                      password=SQL_PASSWORD,\n",
    "                                      sslmode='verify-ca',\n",
    "                                      sslrootcert='AUTH/server-ca.pem',\n",
    "                                      sslkey='AUTH/client.key',\n",
    "                                      sslcert='AUTH/client.crt',\n",
    "                                      database='portal',\n",
    "                                      connect_timeout=3)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"FAILED\", e)\n",
    "    if (pool):\n",
    "        print(\"Connection pool created successfully\")\n",
    "    return pool\n",
    "\n",
    "#setup_firebase()\n",
    "pool = setup_postgres()\n",
    "def get_user_dict():\n",
    "    if not os.path.exists(\"user_dict.pickl\") and pool:\n",
    "        ps_connection  = pool.getconn()\n",
    "        if (ps_connection):\n",
    "            print(\"successfully received connection from connection pool \")\n",
    "            ps_cursor = ps_connection.cursor(cursor_factory = psycopg2.extras.DictCursor)\n",
    "\n",
    "            ps_cursor.execute(\"select uid, email, firstname, lastname, child_list from users_min\")\n",
    "            records = ps_cursor.fetchall()\n",
    "            ps_cursor.close()\n",
    "            #Use this method to release the connection object and send back ti connection pool\n",
    "            pool.putconn(ps_connection)\n",
    "            print(\"Put away a PostgreSQL connection\")\n",
    "\n",
    "            user_dict = {}\n",
    "            for row in records:\n",
    "                user_dict[row['uid']] = {'email': row['email'], 'firstname': row['firstname'], \n",
    "                                         'lastname': row['lastname'], 'childList': row['child_list']}\n",
    "            return user_dict\n",
    "    elif os.path.exists('user_dict.pickl'):\n",
    "        user_dict = pickle.load(open(\"user_dict.pickl\", \"rb\"))\n",
    "        return user_dict\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "user_dict = get_user_dict()\n",
    "setup_firebase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get current data that are in the queue and see which can be send out without changes\n",
    "def GetCompletedTriages(min_time, max_age):\n",
    "    ps_connection = pool.getconn()\n",
    "    ps_cursor = ps_connection.cursor(cursor_factory = psycopg2.extras.NamedTupleCursor)\n",
    "\n",
    "    q = \"\"\"  \n",
    "        SELECT t.*, hist.id, hist.details, hist.agent, hist.time as hist_time, hist.duration, hist.notes \n",
    "        FROM triage as t RIGHT JOIN triage_history as hist on t.triage_key = hist.triage_key \n",
    "        WHERE t.status = %s AND t.time >= %s and t.age <= %s ORDER BY t.time desc;\n",
    "        \"\"\"\n",
    "    \n",
    "    ps_cursor.execute(q, ('Done', min_time, max_age))\n",
    "\n",
    "    triage_dict = {}\n",
    "    for rec in ps_cursor:\n",
    "        t = rec._asdict()\n",
    "        key = t['triage_key']\n",
    "        if key not in triage_dict:\n",
    "            triage_dict[key] = {'uid': t['uid'],\n",
    "                                'cid': t['cid'],\n",
    "                                'age': t['age'],\n",
    "                                'sql_key': key,\n",
    "                                'status': t['status'],\n",
    "                                'due': t['due'],\n",
    "                                'time': t['time'],\n",
    "                                'turnaround_time': t['turnaround_time'],\n",
    "                                'rec_request_key': t['rec_request_key'],\n",
    "                                'request': t['request'],\n",
    "                               }\n",
    "            if t['assignee']:\n",
    "                triage_dict[key]['assignee'] = t['assignee']\n",
    "            if t['generate']:\n",
    "                triage_dict[key]['generate'] = t['generate']\n",
    "                \n",
    "            triage_dict[key]['history'] = {}\n",
    "    \n",
    "        if t['details'] == 'recs_history':\n",
    "            triage_dict[key]['recs_history'] = t['notes']\n",
    "        else:            \n",
    "            history = triage_dict[key]['history']\n",
    "            history_id = t['id']\n",
    "            history[history_id] = {'time': t['hist_time']}\n",
    "            if t['agent']:\n",
    "                history[history_id]['agent'] = t['agent']\n",
    "            if t['notes']:\n",
    "                history[history_id]['notes'] = t['notes']\n",
    "            if t['details']:\n",
    "                history[history_id]['details'] = t['details']\n",
    "            if t['duration']:\n",
    "                history[history_id]['duration'] = t['duration']\n",
    "    \n",
    "    for case_id in list(triage_dict.keys()):\n",
    "        v = triage_dict[case_id]\n",
    "        no_change = 0\n",
    "        change = 0\n",
    "        for k, h in v['history'].items():\n",
    "            if 'details' not in h:\n",
    "                continue\n",
    "            if h['details'] == 'FQ_noChangeNeeded':\n",
    "                no_change += 1\n",
    "            if h['details'] == 'FQ_yesChangeNeeded':\n",
    "                change += 1\n",
    "        if change + no_change > 1 or change + no_change == 0:\n",
    "            del triage_dict[case_id]\n",
    "                \n",
    "    pool.putconn(ps_connection)\n",
    "    \n",
    "    #we also need to add in recs_history\n",
    "    return triage_dict\n",
    "\n",
    "reorder_triages = GetCompletedTriages(1619850739, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main: starting\n",
      "{} user rec dowloaded 0\n",
      "{} user rec dowloaded 100\n",
      "{} user rec dowloaded 200\n",
      "{} user rec dowloaded 300\n",
      "{} user rec dowloaded 400\n",
      "{} user rec dowloaded 500\n",
      "{} user rec dowloaded 600\n",
      "{} user rec dowloaded 700\n",
      "{} user rec dowloaded 800\n",
      "{} user rec dowloaded 900\n",
      "{} user rec dowloaded 1000\n",
      "{} user rec dowloaded 1100\n",
      "{} user rec dowloaded 1200\n",
      "{} user rec dowloaded 1300\n",
      "{} user rec dowloaded 1400\n",
      "{} user rec dowloaded 1500\n",
      "{} user rec dowloaded 1600\n",
      "{} user rec dowloaded 1700\n",
      "{} user rec dowloaded 1800\n",
      "{} user rec dowloaded 1900\n",
      "{} user rec dowloaded 2000\n",
      "{} user rec dowloaded 2100\n",
      "{} user rec dowloaded 2200\n",
      "{} user rec dowloaded 2300\n",
      "{} user rec dowloaded 2400\n",
      "{} user rec dowloaded 2500\n",
      "{} user rec dowloaded 2600\n",
      "{} user rec dowloaded 2700\n",
      "{} user rec dowloaded 2800\n",
      "{} user rec dowloaded 2900\n",
      "{} user rec dowloaded 3000\n",
      "{} user rec dowloaded 3100\n",
      "{} user rec dowloaded 3200\n",
      "{} user rec dowloaded 3300\n",
      "{} user rec dowloaded 3400\n",
      "{} user rec dowloaded 3500\n",
      "{} user rec dowloaded 3600\n",
      "{} user rec dowloaded 3700\n",
      "{} user rec dowloaded 3800\n"
     ]
    }
   ],
   "source": [
    "# read it with threads\n",
    "from concurrent import futures\n",
    "\n",
    "def get_draft_recommendations_in_triages(triages, print_debug=False):\n",
    "    dbrecs = {}\n",
    "    def get_draft_recommendations(cid):\n",
    "        recs = db.reference('draft_recommendations/'+cid).get()\n",
    "        dbrecs[cid] = recs\n",
    "\n",
    "    ex = futures.ThreadPoolExecutor(max_workers=4)\n",
    "    if print_debug:\n",
    "        print('main: starting')\n",
    "    wait_for = [\n",
    "        ex.submit(get_draft_recommendations, v['cid'])\n",
    "        for k, v in triages.items()\n",
    "    ]\n",
    "\n",
    "    i = 0\n",
    "    for f in futures.as_completed(wait_for):\n",
    "        if i % 100 == 0 and print_debug:\n",
    "            print(\"{} user rec dowloaded\", i)\n",
    "        i += 1\n",
    "    return dbrecs\n",
    "        \n",
    "dbrecs = get_draft_recommendations_in_triages(reorder_triages, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_recs_after_time(dbrecs, timestamp):\n",
    "    #keep last years data for dbrecs\n",
    "    last_year_recs = {}\n",
    "    for cid, recs in dbrecs.items():\n",
    "        if isinstance(recs, list):\n",
    "            continue\n",
    "    \n",
    "        if not recs:\n",
    "            continue\n",
    "            \n",
    "        new_recs = {}\n",
    "        for recdate, rec in recs.items():\n",
    "            if int(recdate) < timestamp:\n",
    "                continue\n",
    "            new_recs[recdate] = rec\n",
    "    \n",
    "        if new_recs:\n",
    "            last_year_recs[cid] = new_recs\n",
    "    return last_year_recs\n",
    "\n",
    "last_year_recs = keep_recs_after_time(dbrecs, 1626984685)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sleep_consultant_id_name(fsdb):\n",
    "    docs = fsdb.collection(u'admins').stream()\n",
    "    name_to_assignee = {}\n",
    "    for doc in docs:\n",
    "        data = doc.to_dict()\n",
    "        if not data['assignable']:\n",
    "            continue\n",
    "        name_to_assignee[doc.to_dict()['display_name']] = doc.id\n",
    "    \n",
    "    return {v:k for k, v in name_to_assignee.items()}\n",
    "\n",
    "fsdb = firestore.client()\n",
    "assignee_to_name = get_sleep_consultant_id_name(fsdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "import re\n",
    "import datetime as dt\n",
    "import delorean as dn\n",
    "from diff_match_patch import diff_match_patch\n",
    "import multiprocessing as mp\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleantext = BeautifulSoup(html.unescape(raw_html)).get_text()\n",
    "    cleantext = unicodedata.normalize(\"NFKD\", cleantext)\n",
    "    #return ''.join(cleantext.splitlines())\n",
    "    return cleantext\n",
    "\n",
    "def textdiff(text1,text2, print_debug=False):\n",
    "    added = 0\n",
    "    subbed = 0\n",
    "    \n",
    "    if print_debug:\n",
    "        print(text1)\n",
    "        print(text2)\n",
    "    dmp = diff_match_patch()\n",
    "    \n",
    "    #there is something going on with the timeout when running 4 process at the same time\n",
    "    #maybe CPU throttle or vm issues. setting timeout to 2.5 to get good results\n",
    "    dmp.Diff_Timeout = 0\n",
    "    diff = dmp.diff_main(text1, text2)\n",
    "    \n",
    "    if print_debug:\n",
    "        print(diff)\n",
    "    dmp.diff_cleanupSemantic(diff)\n",
    "    if print_debug:\n",
    "        print(\"after cleaning\")\n",
    "        print(diff)\n",
    "    sentences_added = []\n",
    "    sentences_subbed = []\n",
    "    comp = ''\n",
    "    \n",
    "\n",
    "    for d in diff:\n",
    "        if not d[1].strip():\n",
    "            continue\n",
    "        \n",
    "        if d[0] == 1:\n",
    "            added += len(d[1])\n",
    "            comp += '+'\n",
    "            if len(d[1]) > 80:\n",
    "                sentences_added.append(d[1].strip())\n",
    "        elif d[0] == -1:\n",
    "            subbed += len(d[1])\n",
    "            comp += '-'\n",
    "            if len(d[1]) > 80:\n",
    "                sentences_subbed.append(d[1].strip()) #removal\n",
    "        else:\n",
    "            comp += ' '\n",
    "            \n",
    "        \n",
    "    return {'add':added,'sub':subbed, 'compare':comp, \n",
    "            'sentences_added': sentences_added,\n",
    "            'sentences_subbed': sentences_subbed}\n",
    "\n",
    "def alignRecs(finalrecs,autorecs):\n",
    "    aligned = []\n",
    "    for autorec in autorecs:\n",
    "        if 'type' in autorec:\n",
    "            if autorec['type'] == 'Schedule':\n",
    "                autorec['htmltext'] = '<table>'\n",
    "                for entry in autorec['entries']:\n",
    "                    autorec['htmltext'] += '<tr><td width=140px>' + entry['description'] +'</td><td>' + entry['time'] + '</td></tr>'\n",
    "                autorec['htmltext'] += '</table>'\n",
    "            elif autorec['type'] == 'Divider':\n",
    "                autorec['description'] = autorec['description']+' (div)'\n",
    "\n",
    "    rec_index = 0\n",
    "    rec_key = -1\n",
    "    for finalrec in finalrecs:\n",
    "        rec_key += 1\n",
    "        cur_source = 'skip'\n",
    "        finalrec['draft_index'] = rec_index\n",
    "        if 'type' in finalrec:\n",
    "            if finalrec['type'] == 'Schedule':\n",
    "                finalrec['htmltext'] = '<table>'\n",
    "                for entry in finalrec['entries']:\n",
    "                    finalrec['htmltext'] += '<tr><td width=140px>' + entry['description'] + '</td><td>' + entry['time'] + '</td></tr>'\n",
    "                finalrec['htmltext'] += '</table>'\n",
    "            elif finalrec['type'] == 'Divider':\n",
    "                finalrec['description'] = finalrec['description']+' (div)'\n",
    "\n",
    "        if 'rec_sig' in finalrec:\n",
    "            if 'source' in finalrec['rec_sig']:\n",
    "                cur_source = finalrec['rec_sig']['source']\n",
    "\n",
    "        used_flag = 0\n",
    "        if cur_source != 'skip':\n",
    "            auto_key = -1\n",
    "            for autorec in autorecs:\n",
    "                auto_key += 1\n",
    "                if 'rec_sig' in autorec:\n",
    "                    if 'source' in autorec['rec_sig']:\n",
    "                        if cur_source == autorec['rec_sig']['source']:\n",
    "                            aligned.append([finalrec,autorec])\n",
    "                            autorec['used'] = rec_key\n",
    "                            used_flag = 1\n",
    "\n",
    "        #try matching rec tag\n",
    "        if used_flag == 0:\n",
    "            cur_source = 'skip'\n",
    "            if 'rectag' in finalrec:\n",
    "                cur_source = finalrec['rectag']\n",
    "                if cur_source != 'skip':\n",
    "                    for autorec in autorecs:\n",
    "                        if 'rectag' in autorec:\n",
    "                            if cur_source == autorec['rectag']:\n",
    "                                aligned.append([finalrec,autorec])\n",
    "                                autorec['used'] = rec_key\n",
    "                                used_flag = 1\n",
    "\n",
    "        #try matching descriptions\n",
    "        if used_flag == 0:\n",
    "            cur_source = 'skip'\n",
    "            if 'description' in finalrecs[rec_key]:\n",
    "                cur_source = finalrec['description']\n",
    "\n",
    "                cur_source_strp = stripTAG(cur_source)\n",
    "\n",
    "                if cur_source != 'skip':\n",
    "                    auto_key = -1\n",
    "                    for autorec in autorecs:\n",
    "                        auto_key += 1\n",
    "                        if 'description' in autorec:\n",
    "\n",
    "                            auto_des_strp = stripTAG(autorec['description'])\n",
    "\n",
    "                            if auto_des_strp in cur_source_strp:\n",
    "                                if 'type' in finalrec:\n",
    "                                    cur_type = finalrec['type']\n",
    "                                    if 'type' in autorec:\n",
    "                                        if autorec['type'] == cur_type:\n",
    "                                            aligned.append([finalrec,autorec])\n",
    "                                            autorec['used'] = rec_key\n",
    "                                            used_flag = 1\n",
    "\n",
    "        if used_flag == 0:\n",
    "            aligned.append([finalrec,{'description':'','htmltext':''}])\n",
    "\n",
    "    #unused recs\n",
    "    auto_key = -1\n",
    "    for autorec in autorecs:\n",
    "        auto_key += 1\n",
    "        if 'used' in autorec:\n",
    "            ok = 1\n",
    "        else:\n",
    "            if auto_key == 0:\n",
    "                aligned.insert(0,[{'description':'','htmltext':''},autorec])\n",
    "            else:\n",
    "                #check position of previous card\n",
    "                previous_description = autorecs[auto_key-1]['description']\n",
    "                insert_position = -1\n",
    "                previous_position = -1\n",
    "                for cur_aligned in aligned:\n",
    "                    previous_position += 1\n",
    "                    if cur_aligned[1]['description'] == previous_description:\n",
    "                        insert_position = int(previous_position) + 1\n",
    "\n",
    "                if int(insert_position) == -1:\n",
    "                    aligned.append([{'description':'','htmltext':''},autorec])\n",
    "                elif insert_position == len(aligned):\n",
    "                    aligned.append([{'description':'','htmltext':''},autorec])\n",
    "                else:\n",
    "                    aligned.insert(int(insert_position),[{'description':'','htmltext':''},autorec])\n",
    "    return aligned\n",
    "\n",
    "def stripTAG(string_input):\n",
    "    if string_input[0:3] == 'NEW':\n",
    "        string_output = string_input[3:].strip()\n",
    "    elif string_input[0:7] == 'UPDATED':\n",
    "        string_output = string_input[7:].strip()\n",
    "    else:\n",
    "        string_output = string_input\n",
    "    return string_input\n",
    "\n",
    "def format_recs(recs_to_format, key):\n",
    "    temp_recs = []\n",
    "    ii = 0\n",
    "    for rec in recs_to_format:\n",
    "        thisrec = {}\n",
    "        cur = rec\n",
    "        thisrec['key'] = key\n",
    "        thisrec['id'] = ii\n",
    "        ii+=1\n",
    "        thisrec['type'] = cur['type']\n",
    "        if 'rec_tag' in cur:\n",
    "            thisrec['rectag'] = cur['rectag']\n",
    "        thisrec['description'] = cur['description']\n",
    "        if cur['rec_sig'] != None:\n",
    "            thisrec['rec_sig'] = cur['rec_sig']\n",
    "        if cur['type'] == \"Schedule\":\n",
    "            thisrec['entries'] = cur['entries']\n",
    "            thisrec['htmltext'] = '<table>'\n",
    "            for entry in cur['entries']:\n",
    "                thisrec['htmltext'] += '<tr><td width=140px>' + entry['description'] + '</td><td>' + entry['time'] + '</td></tr>'\n",
    "            thisrec['htmltext'] += '</table>'\n",
    "        else:\n",
    "            temp = cur['text']\n",
    "            #replace newline\n",
    "            temp = temp.replace(\"\\n\", \"\")\n",
    "            thisrec['htmltext'] = temp\n",
    "\n",
    "        temp_recs.append(thisrec)\n",
    "    return temp_recs\n",
    "\n",
    "def compare_chooseDate(editted_recs, auto_recs, key):\n",
    "    diff_output = []\n",
    "    \n",
    "    original_recs = format_recs(auto_recs, key)\n",
    "    aligned = alignRecs(editted_recs, original_recs)\n",
    "    \n",
    "    for alignedrec in aligned:\n",
    "        sentences_added = []\n",
    "        sentences_subbed = []\n",
    "        if 'description' in alignedrec[0]:\n",
    "            cur_rec_des = alignedrec[0]['description']\n",
    "            cur_rec_des = cleanhtml(cur_rec_des)\n",
    "        else:\n",
    "            cur_rec_des = ''\n",
    "        \n",
    "        if 'description' in alignedrec[1]:\n",
    "            cur_auto_des = alignedrec[1]['description']\n",
    "            cur_auto_des = cleanhtml(cur_auto_des)\n",
    "        else:\n",
    "            cur_auto_des = ''\n",
    "        \n",
    "        diff_out = textdiff(cur_auto_des,cur_rec_des)\n",
    "        \n",
    "        added = int(diff_out['add'])\n",
    "        subbed = int(diff_out['sub'])\n",
    "        \n",
    "       \n",
    "        sentences_added.append(tuple(diff_out['sentences_added']))\n",
    "        sentences_subbed.append(tuple(diff_out['sentences_subbed']))\n",
    "\n",
    "        \n",
    "        if 'htmltext' in alignedrec[0]:\n",
    "            cur_rec_text = alignedrec[0]['htmltext']\n",
    "            if 'type' in alignedrec[0]:\n",
    "                if alignedrec[0]['type'] != \"Schedule\":\n",
    "                    cur_rec_text = cleanhtml(cur_rec_text)\n",
    "        else:\n",
    "            cur_rec_text = ''\n",
    "\n",
    "        if 'htmltext' in alignedrec[1]:\n",
    "            cur_auto_text = alignedrec[1]['htmltext']\n",
    "            if 'type' in alignedrec[1]:\n",
    "                if alignedrec[1]['type'] != \"Schedule\":\n",
    "                    cur_auto_text = cleanhtml(cur_auto_text)\n",
    "        else:\n",
    "            cur_auto_text = ''\n",
    "\n",
    "        diff_out = textdiff(cur_auto_text,cur_rec_text)\n",
    "        \n",
    "        added += int(diff_out['add'])\n",
    "        subbed += int(diff_out['sub'])\n",
    "        \n",
    "        sentences_added.append(tuple(diff_out['sentences_added']))\n",
    "       \n",
    "        sentences_subbed.append(tuple(diff_out['sentences_subbed']))\n",
    "\n",
    "                \n",
    "        diff_output.append(({'description':cur_rec_des,'text':cur_rec_text},\n",
    "                            {'description':cur_auto_des,'text':cur_auto_text},\n",
    "                            {'add':added, 'sub':subbed},\n",
    "                            {'sentences_added': sentences_added, 'sentences_subbed': sentences_subbed}))\n",
    "    return diff_output\n",
    "                                         \n",
    "def parse_output(compare_output):\n",
    "    compared_list = []\n",
    "    for aligned in compare_output:\n",
    "        if aligned[1] == {'description': '', 'text': ''}:\n",
    "            cur_status = 'added'\n",
    "            title = aligned[0]['description']\n",
    "        elif aligned[0] == {'description': '', 'text': ''}:\n",
    "            cur_status = 'removed'\n",
    "            title = aligned[1]['description']\n",
    "        else:\n",
    "            cur_status = '+:'+str(aligned[3]['add'])+',-:'+str(aligned[3]['sub'])\n",
    "            title = aligned[0]['description']\n",
    "        compared_list.append({'status':cur_status,'title':title})\n",
    "    return compared_list\n",
    "\n",
    "def compare_rec_with_autogen(triage, assignee_name, childList, cur_time, drecs):\n",
    "    key = triage['sql_key']\n",
    "    cid = triage.get('cid', '') or triage.get('uid', '')\n",
    "    uid = triage['uid']\n",
    "    \n",
    "    assignee_name\n",
    "    \n",
    "    request = triage['request']\n",
    "    status = triage['status']\n",
    "    \n",
    "    output = {}\n",
    "\n",
    "    #bug since we are actually looping through all the recommendations for a child and it may not\n",
    "    #be the first one\n",
    "\n",
    "    for new_recdate, new_rec_space in drecs.items():\n",
    "        try:\n",
    "            creation_sig = new_rec_space['rec_signature']['creation_sig']\n",
    "            \n",
    "            if 'request_key' not in creation_sig:\n",
    "                continue\n",
    "                \n",
    "            if creation_sig['request_key'] != triage['rec_request_key']:\n",
    "                continue\n",
    "            \n",
    "            if 'auto_gen' not in new_rec_space:\n",
    "                continue\n",
    "            \n",
    "            if new_rec_space['notUL'] == 1:\n",
    "                continue\n",
    "                \n",
    "            auto_recs = new_rec_space['auto_gen']['rec_json']\n",
    "            editted_recs = new_rec_space['rec_json']\n",
    "            email = user_dict[uid]['email']\n",
    "            \n",
    "            out_put = compare_chooseDate(editted_recs, auto_recs, key)\n",
    "\n",
    "            consultant = assignee_name\n",
    "            age = triage['age']\n",
    "            id_ = new_rec_space['rec_signature']['_id']\n",
    "            searchArray = new_rec_space['auto_gen']['rec_signature']['searchArray']\n",
    "            creation_sig = new_rec_space['rec_signature']['creation_sig']\n",
    "            child = ''\n",
    "            for entry in childList:\n",
    "                if entry['cid'] == cid:\n",
    "                    child = entry['nickname']\n",
    "            \n",
    "            output = {'id': id_, 'creation_sig': creation_sig, 'searchArray': searchArray, 'age':age,\n",
    "                      'output':out_put,'date':cur_time,'email':email,'child':child,'uid':uid,'cid':cid,\n",
    "                      'consultant':consultant,'key':key}\n",
    "            \n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"exception\", e)\n",
    "            \n",
    "    return output\n",
    "\n",
    "def compare_recs(triages, dbrecs, user_dict, assignee_to_name):\n",
    "    triage_compare_list = []\n",
    "    cur_time = dn.epoch(dt.datetime.now().timestamp()).shift('America/Los_Angeles').datetime.strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    for key, cur_entry in triages.items():\n",
    "        if ('uid' not in cur_entry or 'assignee' not in cur_entry or \n",
    "            'request' not in cur_entry or 'status' not in cur_entry):\n",
    "            continue\n",
    "        \n",
    "        cid = cur_entry.get('cid', '') or cur_entry.get('uid', '')\n",
    "        assignee = cur_entry['assignee']\n",
    "        if assignee not in assignee_to_name:\n",
    "            continue\n",
    "\n",
    "        assignee_name = assignee_to_name[assignee]\n",
    "        uid = cur_entry['uid']\n",
    "        request = cur_entry['request']\n",
    "        status = cur_entry['status']\n",
    "\n",
    "        if (request == \"CC full analysis\" or request == 'EA full analysis') and (status == \"Done\"):\n",
    "            if cid not in dbrecs:\n",
    "                continue\n",
    "            \n",
    "            drecs = dbrecs[cid]        \n",
    "            childList = user_dict[uid]['childList']\n",
    "            output = compare_rec_with_autogen(cur_entry, assignee_name, childList, cur_time, drecs)\n",
    "            \n",
    "            if output:\n",
    "                triage_compare_list.append(output)\n",
    "    \n",
    "    return triage_compare_list\n",
    "\n",
    "def compare_recs_mp(triages, dbrecs, user_dict, assignee_to_name):\n",
    "    data_for_cmp = []\n",
    "    cur_time = dn.epoch(dt.datetime.now().timestamp()).shift('America/Los_Angeles').datetime.strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    def generate_data():\n",
    "        for key, cur_entry in triages.items():\n",
    "            if ('uid' not in cur_entry or \n",
    "                'request' not in cur_entry or 'status' not in cur_entry):\n",
    "                print(\"uid/request/status\", cur_entry)\n",
    "                continue\n",
    "        \n",
    "            cid = cur_entry.get('cid', '') or cur_entry.get('uid', '')\n",
    "            assignee = cur_entry.get('assignee', '123')\n",
    "            \n",
    "            assignee_name = assignee_to_name.get(assignee, \"unknown\")\n",
    "            uid = cur_entry['uid']\n",
    "            request = cur_entry['request']\n",
    "            status = cur_entry['status']\n",
    "            if uid not in user_dict:\n",
    "                print(\"uid not in user_dict\", uid)\n",
    "                continue\n",
    "            \n",
    "            if (request == \"CC full analysis\" or request == 'EA full analysis') and (status == \"Done\") and cid in dbrecs:\n",
    "                drecs = dbrecs[cid]\n",
    "                childList = user_dict[uid]['childList']\n",
    "                yield (cur_entry, assignee_name, childList, cur_time, drecs)\n",
    "    \n",
    "    \n",
    "    with mp.Pool(processes=mp.cpu_count(), maxtasksperchild=100) as pool:\n",
    "        triage_compare_list = pool.starmap(compare_rec_with_autogen, generate_data())\n",
    "    \n",
    "    return triage_compare_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_triaage_list = compare_recs_mp(reorder_triages, last_year_recs, user_dict, assignee_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_history(triage):\n",
    "    history = {'SA': 0, 'toofew': 0, 'vip': 0, 'rec_history': 0, 'manynotes': 0, 'question': 0, 'cur_age': 0}\n",
    "    notes_history = triage.get('history', {})\n",
    "    \n",
    "    nweeks = 10\n",
    "    nrecs = 20\n",
    "    nw_number = 0\n",
    "    \n",
    "    re_nweeks = re.compile(r\"(\\d+)(Weeks|W)\")\n",
    "    re_nrecs = re.compile(r\"(\\d+)(Recs|R)\")\n",
    "    \n",
    "    for (time_key, history_entry) in sorted(notes_history.items()):\n",
    "        agent = history_entry.get('agent', '')\n",
    "#         if not agent or agent != 'autogen':\n",
    "#             continue\n",
    "            \n",
    "        notes = history_entry.get(\"notes\", '')\n",
    "        if notes == '':\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        notes = notes.split(',')\n",
    "        for note in notes:\n",
    "            note = note.strip()\n",
    "            if 'VIP' in note:\n",
    "                history['vip'] = 1\n",
    "        \n",
    "            if 'SA' in note:\n",
    "                history['SA'] = 1\n",
    "            \n",
    "            if \"NW \" in note:\n",
    "                try:\n",
    "                    nw_number=int(note.replace(\"NW\",\"\").strip())\n",
    "                    if nw_number > 200:\n",
    "                        history['manynotes'] = 1\n",
    "                except Exception as e:\n",
    "                    print(note)\n",
    "            \n",
    "            if 'sibling' in note:\n",
    "                history['rec_history'] = 1 \n",
    "        \n",
    "            m = re_nweeks.match(note)\n",
    "            if m:\n",
    "                nweeks = int(m.group(1))\n",
    "          \n",
    "                \n",
    "            m = re_nrecs.match(note)\n",
    "            if m:\n",
    "                nrecs = int(m.group(1))\n",
    "\n",
    "    history['toofew'] = 1 if (nweeks < 4 or nrecs < 8) else 0\n",
    "    history['nweeks'] = nweeks\n",
    "    history['nrecs'] = nrecs\n",
    "    history['nw_number'] = nw_number\n",
    "    recs_history = triage.get(\"recs_history\", \"\")\n",
    "    if recs_history:\n",
    "        num_recs_history = len(recs_history.splitlines())\n",
    "        history['rec_history'] = 2 if num_recs_history > 2 else 1\n",
    "        \n",
    "    triage_req = triage.get('request', {})\n",
    "    history['question'] = 1 if 'question' in triage_req else 0\n",
    "    history['cur_age'] = triage.get(\"age\", 0) if triage_req else 0\n",
    "    return history\n",
    "\n",
    "def case_classifier(triage):\n",
    "    history = get_history(triage)\n",
    "    rec_type = []\n",
    "    rec_type_dict = {'vip': -1, 'repeat': -1, 'greater2': -1, 'toofew': -1,\n",
    "                     'manynotes': -1, 'less4month': -1, 'greater11month': -1,\n",
    "                     'SA': -1, 'general': -1, 'question': -1}\n",
    "\n",
    "    if history['question']:\n",
    "        rec_type.append('question')\n",
    "        rec_type_dict['question'] = 1\n",
    "    else:\n",
    "        if history['vip']:\n",
    "            rec_type.append('vip')\n",
    "            rec_type_dict['vip'] = 1\n",
    "        if history['rec_history'] == 1 or history['rec_history'] == 2:\n",
    "            rec_type.append(\"repeat\")\n",
    "            rec_type_dict['repeat'] = 1\n",
    "        if history['rec_history'] == 2:\n",
    "            rec_type.append('+2')\n",
    "            rec_type_dict['greater2'] = 1\n",
    "        if history['toofew']:\n",
    "            rec_type.append('toofew')\n",
    "            rec_type_dict['toofew'] = 1\n",
    "        if history['cur_age'] < 4:\n",
    "            rec_type.append('<4m')\n",
    "            rec_type_dict['less4month'] = 1\n",
    "        if history['manynotes']:\n",
    "            rec_type.append('manynotes')\n",
    "            rec_type_dict['manynotes'] = 1\n",
    "        if history['cur_age'] > 11:\n",
    "            rec_type.append('>11m')\n",
    "            rec_type_dict['greater11month'] = 1\n",
    "        if history['SA']:\n",
    "            rec_type.append('SA')\n",
    "            rec_type_dict['SA'] = 1\n",
    "        if not rec_type:\n",
    "            rec_type.append('general')\n",
    "            rec_type_dict['general'] = 1\n",
    "    rec_type_dict['nweeks'] = history['nweeks']\n",
    "    rec_type_dict['nrecs'] = history['nrecs']\n",
    "    rec_type_dict['nw_number'] = history['nw_number']\n",
    "        \n",
    "    return rec_type, rec_type_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triage_features(triages):\n",
    "    triage_features = {}\n",
    "    for _, triage in triages.items(): \n",
    "        rec_request_key = triage.get('rec_request_key', '')\n",
    "        if rec_request_key == '':\n",
    "            continue\n",
    "        _, features = case_classifier(triage)\n",
    "        for t, hist in triage['history'].items():\n",
    "            if 'details' in hist and hist['details'] == 'FQ_yesChangeNeeded':\n",
    "                features['NoChangeNeeded'] = 0\n",
    "        \n",
    "        for t, hist in triage['history'].items():\n",
    "            if 'details' in hist and hist['details'] == 'FQ_noChangeNeeded':\n",
    "                features['NoChangeNeeded'] = 1\n",
    "                \n",
    "        if 'NoChangeNeeded' not in features:\n",
    "            features['NoChangeNeeded'] = -5\n",
    "        triage_features[rec_request_key] = features\n",
    "        \n",
    "        \n",
    "    return triage_features\n",
    "    \n",
    "triage_features = get_triage_features(reorder_triages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = 0\n",
    "yes = 0\n",
    "for k, v in triage_features.items():\n",
    "    if v['NoChangeNeeded'] == 1:\n",
    "        no += 1\n",
    "    elif v['NoChangeNeeded'] == 0:\n",
    "        yes += 1\n",
    "    \n",
    "print(\"no, yes\", no, yes, no/(no+yes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFirstReq(reorder_triage):\n",
    "    first_time_triage = set()\n",
    "    req_key_to_triage = {}\n",
    "    triage_to_consultant = {}\n",
    "    for _, t in reorder_triage.items():\n",
    "        if 'assignee' in t and t['assignee'] not in assignee_to_name:\n",
    "            continue\n",
    "        if 'recs_history' not in t:\n",
    "            first_time_triage.add(t['sql_key'])\n",
    "        if 'rec_request_key' in t:\n",
    "            req_key_to_triage[t['rec_request_key']] = t['sql_key']\n",
    "        if 'assignee' in t:\n",
    "            triage_to_consultant[t['sql_key']] = assignee_to_name[t['assignee']]\n",
    "        else:\n",
    "            triage_to_consultant[t['sql_key']] = 'nobody'\n",
    "    return first_time_triage, req_key_to_triage, triage_to_consultant\n",
    "\n",
    "first_time_triage, req_key_to_triage, triage_to_consultant = GetFirstReq(reorder_triages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uid': 'Ap0Gn4PJaNMcDYZe3gOJvLzQHbE3', 'cid': 'Ap0Gn4PJaNMcDYZe3gOJvLzQHbE3', 'age': 2, 'sql_key': 86936, 'status': 'Done', 'due': 1628070589, 'time': 1627379389, 'turnaround_time': '8 US business days', 'rec_request_key': '1627379389995-782c3e06a6f9b2a59791', 'request': 'CC full analysis', 'assignee': 'vv7HgbZWahR8d0GNfLZB75X4Puw2', 'generate': 1628529396, 'history': {'1628640615': {'time': 1628640616, 'agent': 'gkOWK8FwkaZkI4walq0K2Nmkp8p1', 'details': 'Updated'}, '1627420241450': {'time': 1627420241, 'agent': 'XGB', 'details': 'XGB Prediction'}, '1628525252': {'time': 1628525253, 'agent': 'rjSWYxkxIfhUB7qJ5xSPUZt7PEq1', 'notes': 'dec_age: 2.2, 10R, 8W, BDAY mismatch (2021-02-26 7w premature (onboard), 2021-04-16 7w premature (questionnaire))', 'details': 'batch_gen recs - complete'}, '1627419690': {'time': 1627419690, 'agent': 'autogen', 'notes': '***NoTracking Recommendation-noData***', 'details': 'Warnings created'}, '1628525970': {'time': 1628525971, 'agent': 'vv7HgbZWahR8d0GNfLZB75X4Puw2', 'details': 'Uploaded'}, '1627419689': {'time': 1627419689, 'agent': 'autogen', 'notes': 'dec_age: 1.7, 8R, 12W', 'details': 'autogen recs - complete'}, '1628529724': {'time': 1628529725, 'agent': '91E8UHauBuMzcTs70VivEnndr412', 'details': 'Uploaded'}, '1627379390': {'time': 1627379390, 'details': 'Automatically transferred from rec request queue to triage list'}, '1628529772': {'time': 1628529772, 'agent': 'vv7HgbZWahR8d0GNfLZB75X4Puw2', 'details': 'Changed status to Done'}, '1627420241468': {'time': 1627420241, 'agent': 'XGB', 'notes': 'MED_TEXT=swallowing difficulties, hydrocephalus', 'details': 'XGB Prediction'}, '1627881201': {'time': 1627881202, 'agent': 'vv7HgbZWahR8d0GNfLZB75X4Puw2', 'details': 'Uploaded'}, '1627680342': {'time': 1627680342, 'agent': 'regen-nT', 'notes': 'dec_age: 1.8, 8R, 12W', 'details': 'autogen regen-nT recs - complete'}, '1627852542': {'time': 1627852542, 'agent': 'auto_assign', 'details': 'Assigned to Jolan. Change status to Not Started.'}, '1627881210': {'time': 1627881210, 'agent': 'vv7HgbZWahR8d0GNfLZB75X4Puw2', 'notes': ' ', 'details': 'FQ_noChangeNeeded'}, '1627680343': {'time': 1627680343, 'agent': 'regen-nT', 'notes': '**Consider regenerating this case using sleep data**', 'details': 'Warnings created'}, '1627853612': {'time': 1627853612, 'agent': 'regen', 'notes': 'dec_age: 2, 10R, 8W', 'details': 'autogen regen recs - complete'}, '1627681519850': {'time': 1627681519, 'agent': 'XGB_regen', 'notes': 'EXP_NB=0.67', 'details': 'XGB Prediction'}, '1627881211': {'time': 1627881211, 'agent': 'vv7HgbZWahR8d0GNfLZB75X4Puw2', 'details': 'Changed status to Done', 'duration': 10.0}, '1627681519866': {'time': 1627681519, 'agent': 'XGB_regen', 'notes': 'MED_TEXT=swallowing difficulties, hydrocephalus', 'details': 'XGB Prediction'}, '1628529396': {'time': 1628529397, 'agent': '91E8UHauBuMzcTs70VivEnndr412', 'notes': 'dec_age: 2.2, 10R, 8W, BDAY mismatch (2021-02-26 7w premature (onboard), 2021-04-16 7w premature (questionnaire))', 'details': 'batch_gen recs - complete'}, '1628524229': {'time': 1628524229, 'agent': '91E8UHauBuMzcTs70VivEnndr412', 'notes': 'dec_age: 2.2, 11R, 8W, BDAY mismatch (2021-02-26 7w premature (onboard), 2021-04-16 7w premature (questionnaire))', 'details': 'batch_gen recs - complete'}, '1628526118': {'time': 1628526118, 'agent': 'vv7HgbZWahR8d0GNfLZB75X4Puw2', 'details': 'Added additional time', 'duration': -14.0}, '1628525978': {'time': 1628525978, 'agent': 'vv7HgbZWahR8d0GNfLZB75X4Puw2', 'details': 'Changed status to Done', 'duration': 14.0}}, 'recs_history': '20210802'}\n",
      "not first time\n"
     ]
    }
   ],
   "source": [
    "import delorean as dn\n",
    "from collections import defaultdict\n",
    "date_created = []\n",
    "num_changes = []\n",
    "\n",
    "changes_sections = defaultdict(int)\n",
    "\n",
    "num_changes_dict = defaultdict(int)\n",
    "compare_triage_list1 = [d for d in compare_triaage_list if d]\n",
    "\n",
    "for d in compare_triage_list1:\n",
    "    triage_key = d['key']\n",
    "    if triage_key not in reorder_triages:\n",
    "        print(\"missing triage key in reorder_triages\")\n",
    "        continue\n",
    "        \n",
    "    if triage_key not in first_time_triage:\n",
    "        print(reorder_triages[triage_key])\n",
    "        print(\"not first time\")\n",
    "        continue\n",
    "    try:\n",
    "        history = reorder_triages[triage_key]['history']\n",
    "        last_key = sorted(history.keys())[-1]\n",
    "    except Exception as e:\n",
    "        print(reorder_triages[triage_key])\n",
    "    \n",
    "    cid = d['cid']\n",
    "    request_key = d['creation_sig']['request_key']\n",
    "    recs = dbrecs[cid]\n",
    "    #get the right rec\n",
    "    real_rec = None\n",
    "    for rec_date, rec in recs.items():\n",
    "        if 'rec_signature' not in rec:\n",
    "            continue\n",
    "        \n",
    "        if 'creation_sig' not in rec['rec_signature']:\n",
    "            contnue\n",
    "        \n",
    "        if 'request_key' not in rec['rec_signature']['creation_sig']:\n",
    "            continue\n",
    "        if rec['rec_signature']['creation_sig']['request_key'] == request_key:\n",
    "            real_rec = rec\n",
    "            break\n",
    "    \n",
    "    if real_rec is None:\n",
    "        continue\n",
    "    \n",
    "    rec_json = real_rec['rec_json']\n",
    "    timestamp = last_key\n",
    "    output = d['output']\n",
    "    num = 0\n",
    "    for o in output:\n",
    "        if 'div' in o[0]['description'].lower():\n",
    "            continue\n",
    "        \n",
    "        if 'schedule' in o[0]['description'].lower():\n",
    "            continue\n",
    "#         if o[0]['description'].lower() == 'explanation of schedule':\n",
    "#             continue\n",
    "        skip = False\n",
    "        for card in rec_json:\n",
    "            if card['description'] == o[0]['description']:\n",
    "                skip = card['type'] == 'Schedule'\n",
    "                break\n",
    "        if skip:\n",
    "            continue\n",
    "        if o[2]['add'] + o[2]['sub'] < 50:\n",
    "            continue\n",
    "        num += 1\n",
    "        changes_sections\n",
    "    date_created.append(timestamp)\n",
    "    num_changes.append(num)\n",
    "    num_changes_dict[num] += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>num_changes</th>\n",
       "      <th>count</th>\n",
       "      <th>% change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>0.229965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>508</td>\n",
       "      <td>0.354007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>298</td>\n",
       "      <td>0.207666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>0.039721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.009059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>0.027875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.008362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1435\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(num_changes_dict.items(), columns=['num_changes', 'count'])\n",
    "df = df.sort_values(['num_changes'])\n",
    "total = df['count'].sum()\n",
    "df['% change'] = df['count']/total\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(df.to_html(index=False)))\n",
    "print(sum(df['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning of naps\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of naps\n",
      "checkhow < 2\n",
      "Beginning of naps\n",
      "checkhow > 2\n",
      "Beginning of naps\n",
      "checkhow > 2\n",
      "Beginning of naps\n",
      "checkwhy > 2\n",
      "Beginning of naps\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of naps\n",
      "checkhow < 2\n",
      "Beginning of naps\n",
      "checkwhy > 2\n",
      "Beginning of naps\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of naps\n",
      "checkwhy > 2\n",
      "Beginning of naps\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkhow > 2\n",
      "Beginning of naps\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of naps\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of naps\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkhow > 2\n",
      "Beginning of naps\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of naps\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of naps\n",
      "checkwhy > 2\n",
      "Beginning of naps\n",
      "checkwhy > 2\n",
      "Beginning of naps\n",
      "checkhow > 2\n",
      "Beginning of naps\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of naps\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkhow > 2\n",
      "Beginning of naps\n",
      "checkwhy > 2\n",
      "Beginning of naps\n",
      "checkwhy < 2\n",
      "Beginning of naps\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of naps\n",
      "checkwhy < 2\n",
      "Beginning of the night\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of naps\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkhow > 2\n",
      "Beginning of naps\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of naps\n",
      "checkwhy < 2\n",
      "Beginning of the night\n",
      "checkwhy < 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of naps\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkwhy < 2\n",
      "Beginning of the night\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkwhy < 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkwhy > 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of naps\n",
      "checkhow > 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of naps\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkwhy < 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of naps\n",
      "checkhow > 2\n",
      "Beginning of naps\n",
      "checkwhy < 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkwhy < 2\n",
      "Beginning of naps\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkhow < 2\n",
      "Beginning of the night\n",
      "checkhow > 2\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "def get_rec_requests():\n",
    "    \"\"\"Get all the requests\"\"\"\n",
    "    #THIS IS TOO SLOW NOW SINCE WE HAVE MANY REC REQUESTS NOW. MOVE TO USING THREADS\n",
    "    dbrequests = db.reference('rec_requests').get()\n",
    "    rec_request_free_text = defaultdict(list)\n",
    "    \n",
    "    for user_key, request in dbrequests.items():\n",
    "        all_requests = defaultdict(list)\n",
    "        for rec_key, rec in request.items():\n",
    "            cid = user_key\n",
    "            if 'cid' in rec:\n",
    "                cid = rec['cid']\n",
    "            all_requests[cid].append((rec_key, rec['time']))\n",
    "            if 'questionnaire' in rec:\n",
    "                user_q = rec['questionnaire']\n",
    "                for q_key, ques in user_q.items():\n",
    "                    if 'answer' in ques:\n",
    "                        ans = ques['answer']\n",
    "                        if \"multi\" in ques['type']:\n",
    "                            for multi in ans:\n",
    "                                if \"_other\" in multi['label']:\n",
    "                                    other_answer = multi['encode']\n",
    "                                    if other_answer != 'n/a' and other_answer != 'none' and other_answer != 'no' and other_answer != '':\n",
    "                                        rec_request_free_text[rec_key].append((q_key, multi['label'], other_answer))\n",
    "                        elif \"label\" in ques:\n",
    "                            if\"_other\" in ans['label']:\n",
    "                                other_answer = ans['encode'].strip().lower()\n",
    "                                if other_answer != 'n/a' and other_answer != 'none' and other_answer != 'no' and other_answer != '':\n",
    "                                    rec_request_free_text[rec_key].append((q_key, ans['label']), other_answer)\n",
    "                        elif \"textarea\" in ques['type']:\n",
    "                            textarea_answer = ans['encode'].strip().lower()\n",
    "                            if textarea_answer != 'n/a' and textarea_answer != 'none' and textarea_answer != 'no' and textarea_answer != '':\n",
    "                                rec_request_free_text[rec_key].append((q_key, 'textarea', textarea_answer))\n",
    "    \n",
    "\n",
    "    return rec_request_free_text\n",
    "\n",
    "\n",
    "def has_diff(output, rec_schedule=False):\n",
    "    diff_sections = []\n",
    "    for o in output:\n",
    "        c = o[2]\n",
    "        changes = c['add'] + c['sub']\n",
    "        description = o[0]['description'] or o[1]['description']\n",
    "        if ( changes >= 50 and \"optional\" not in description.lower() and \n",
    "            'div' not in description.lower() ):\n",
    "            \n",
    "            #if we want to include schedule changes, then just append it\n",
    "            if rec_schedule:\n",
    "                diff_sections.append(description)\n",
    "            elif 'recommended schedule' not in description.lower():\n",
    "                #if we are not sure about schedule changes, we should check that recommend schedule does not appear\n",
    "                diff_sections.append(description)\n",
    "    \n",
    "    return diff_sections\n",
    "            \n",
    "    \n",
    "def has_warnings(drecs, id_):\n",
    "    auto_rec_json = []\n",
    "    for new_recdate, new_rec_space in drecs.items():\n",
    "        try:\n",
    "            creation_sig = new_rec_space['rec_signature']['creation_sig']\n",
    "            \n",
    "            if 'request_key' not in creation_sig:\n",
    "                continue\n",
    "                \n",
    "            if new_rec_space['rec_signature']['_id'] != id_:\n",
    "                continue\n",
    "            \n",
    "            if 'auto_gen' not in new_rec_space:\n",
    "                continue\n",
    "            \n",
    "            auto_rec_json = new_rec_space['auto_gen']['rec_json']\n",
    "            break\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    for card in auto_rec_json:\n",
    "        if (card['type'] not in ['Schedule', 'Divider'] and\n",
    "            card['description'].strip() not in ['Explanation of schedule', 'Sleep Profile', 'Additional Notes']):\n",
    "        \n",
    "            checkwhy = card['text'].strip().split(\"Why:\")\n",
    "            checkhow = card['text'].strip().split(\"How:\")\n",
    "            checknotes = card['text'].strip().split(\"Notes:\")\n",
    "            checknote = card['text'].strip().split(\"Note:\")\n",
    "            checkAddnotes = card['text'].strip().split(\"Additional Notes:\")\n",
    "            checkqa = card['text'].strip().split(\"Q:\")\n",
    "\n",
    "            if card['description'].strip()=='Beginning of the night':\n",
    "                bOTN = 1\n",
    "            if card['description'].strip()=='Falling asleep at bedtime':\n",
    "                fAABT = 1\n",
    "            if len(checkwhy) > 2:\n",
    "                print(card['description'])\n",
    "                print(\"checkwhy > 2\")\n",
    "                return True\n",
    "            elif len(checkhow) > 2:\n",
    "                print(card['description'])\n",
    "                print(\"checkhow > 2\")\n",
    "                return True\n",
    "            elif len(checkhow) < 2:\n",
    "                print(card['description'])\n",
    "                print(\"checkhow < 2\")\n",
    "                return True\n",
    "            elif len(checkwhy) < 2:\n",
    "                print(card['description'])\n",
    "                print(\"checkwhy < 2\")\n",
    "                return True\n",
    "            elif len(checknotes) > 1 and (checknotes[0] == '' or checknotes[0] == '<strong>'):\n",
    "                print(card['description'])\n",
    "                print(\"checknotes > 1\")\n",
    "                return True\n",
    "            elif len(checknote) > 1 and (checknote[0] == '' or checknote[0] == '<strong>'):\n",
    "                print(card['description'])\n",
    "                print(\"checknote > 1\")\n",
    "                return True\n",
    "            elif len(checkAddnotes) > 1 and (checkAddnotes[0] == '' or checkAddnotes[0] == '<strong>'):\n",
    "                print(card['description'])\n",
    "                print(\"checaddknote > 1\")\n",
    "                return True\n",
    "            elif len(checkqa) > 1 and checkqa[0] == '':\n",
    "                print(card['description'])\n",
    "                print(\"checkqa > 1\")\n",
    "                return True\n",
    "    return False\n",
    "                    \n",
    "def failed_schedule(output):\n",
    "    sentences = ['fail', 'failed', \"total sleep hours in the schedule is less than the minimum required sleep\",\n",
    "                 \"schedule does not follow user's reported parameters\", \"total night hours is\"]\n",
    "    for o in output:\n",
    "        if 'recommended schedule' in o[1]['description'].lower():\n",
    "            text = o[1]['text'].lower()\n",
    "            for s in sentences:\n",
    "                if s in text:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def time_convert(hhmm):\n",
    "    if not isinstance(hhmm, str):\n",
    "        return hhmm\n",
    "    hhmm = hhmm.split(':')\n",
    "    return int(hhmm[0])*3600 + int(hhmm[1])*60\n",
    "\n",
    "def GetTrainingData(rec_request_free_text, triages_compare_list, req_key_to_triage, \n",
    "                    triage_features, consultants_list, useConsultantAnswerForChange=False):\n",
    "    triage_to_t = defaultdict(list)\n",
    "    sleep_training = []\n",
    "    anything_else = []\n",
    "    \n",
    "    for t in triages_compare_list:\n",
    "        if not t or 'creation_sig' not in t or 'request_key' not in t['creation_sig']:\n",
    "            continue\n",
    "    \n",
    "        req_key = t['creation_sig']['request_key']\n",
    "        if req_key not in req_key_to_triage:\n",
    "            continue\n",
    "    \n",
    "        triage_key = req_key_to_triage[req_key]\n",
    "        if triage_key not in first_time_triage:\n",
    "            continue\n",
    "    \n",
    "        if triage_key not in triage_to_consultant:\n",
    "            continue\n",
    "            \n",
    "        triage_to_t[triage_key].append(t)\n",
    "    \n",
    "    searchArrays = []\n",
    "    y = []\n",
    "    for triage_key, t_list in triage_to_t.items():\n",
    "        unique_t = {}\n",
    "        for t in t_list:\n",
    "            unique_t[t['id']] = t\n",
    "        all_ts = []\n",
    "        for _, t in unique_t.items():\n",
    "            all_ts.append(t)\n",
    "        sorted(all_ts, key=lambda x: x['id'], reverse=True)\n",
    "        t = all_ts[0]\n",
    "        age = t['searchArray'].get('age', 0) or t['searchArray'].get('calc_age', -1)\n",
    "        if age < 0:\n",
    "            continue\n",
    "        \n",
    "        if age > 4:\n",
    "            continue\n",
    "            \n",
    "        rec_request_key = t['creation_sig']['request_key']\n",
    "        \n",
    "        if rec_request_key not in triage_features:\n",
    "            continue\n",
    "        \n",
    "        consultant = triage_to_consultant[triage_key]\n",
    "        \n",
    "        if consultant not in consultants_list:\n",
    "            continue\n",
    "        if '_id' in t['searchArray']:\n",
    "            #some screwed up searchArray\n",
    "            tmp = t['searchArray']['searchArray']\n",
    "            t['searchArray'] = tmp\n",
    "        \n",
    "        if '_id' in t['searchArray']:\n",
    "            print(t['searchArray'])\n",
    "            print(asdfsas)\n",
    "        t['searchArray']['uid'] = t['uid']    \n",
    "        t['searchArray']['cid'] = t['cid']\n",
    "        t['searchArray']['email'] = t['email']\n",
    "        t['searchArray']['child'] = t['child']\n",
    "        t['searchArray']['req_key'] = rec_request_key\n",
    "        t['searchArray']['consultant'] = triage_to_consultant[triage_key]\n",
    "        t['searchArray']['free_text'] = 1 if rec_request_key in rec_req_free_txt else 0\n",
    "        has_tried_sleep_training = 0\n",
    "        \n",
    "        gender = t['searchArray'].get('gender', 'NA')\n",
    "        \n",
    "        diff_sections = has_diff(t['output'], False) #ignore schedule\n",
    "        no_diff = 0 if diff_sections else 1\n",
    "        \n",
    "        sleep_training_note = ''\n",
    "       \n",
    "        if t['searchArray']['free_text'] == 1:\n",
    "            for (qkey, label, ans) in rec_req_free_txt[rec_request_key]:\n",
    "                if qkey == '30173308':\n",
    "                    sleep_training_note = ans\n",
    "                    sleep_training.append((t['uid'], t['cid'], t['email'], age, gender, ans, no_diff))\n",
    "                \n",
    "        other_ans = []\n",
    "        for (qkey, label, ans) in rec_req_free_txt[rec_request_key]:\n",
    "            if '_other' in label:\n",
    "                other_ans.append(ans)\n",
    "                \n",
    "        t['searchArray']['other_ans'] = ' '.join(other_ans)\n",
    "        t['searchArray']['other_len'] = len(t['searchArray']['other_ans'])\n",
    "        t['searchArray']['slee_training'] = sleep_training_note\n",
    "        t['searchArray']['sleep_training_len'] = len(sleep_training_note)\n",
    "        \n",
    "        if 'anything_else' in t['searchArray']:\n",
    "            t['searchArray']['anything_else_length'] = len(t['searchArray']['anything_else'])\n",
    "            anything_else.append((t['uid'], t['cid'], t['email'], age, gender, t['searchArray']['anything_else'], no_diff))\n",
    "        else:\n",
    "            t['searchArray']['anything_else_length'] = 0\n",
    "        for k, v in triage_features[rec_request_key].items():\n",
    "            if k == 'NoChangeNeeded':\n",
    "                continue\n",
    "            t['searchArray'][k] = v\n",
    "        \n",
    "       \n",
    "        if 'NoChangeNeeded' in t['searchArray']:\n",
    "            del t['searchArray']['NoChangeNeeded']\n",
    "        cid = t['cid']\n",
    "        t['searchArray']['bad_schedule'] = failed_schedule(t['output'])\n",
    "        t['searchArray']['has_warning'] = has_warnings(dbrecs[cid], t['id'])\n",
    "       \n",
    "        if 'recWakeUpTime' in t['searchArray']:\n",
    "            t['searchArray']['desired_diff_wakeup'] = t['searchArray']['recWakeUpTime'] - t['searchArray']['uiDesiredWakeup']\n",
    "        if 'recNightStartTime' in t['searchArray']:\n",
    "            t['searchArray']['desired_diff_bedtime'] = t['searchArray']['recNightStartTime'] - t['searchArray']['earliestGetforBedtime']\n",
    "        searchArrays.append(t['searchArray'])\n",
    "        for diff_section in diff_sections:\n",
    "            colname = 'diffSection_'+diff_section\n",
    "            t['searchArray'][colname] = 0\n",
    "            if diff_section in t['searchArray']:\n",
    "                del t['searchArray'][diff_section]\n",
    "        \n",
    "        \n",
    "        feature = triage_features[rec_request_key]\n",
    "        if useConsultantAnswerForChange:\n",
    "            if 'NoChangeNeeded' in feature:\n",
    "                y.append(feature['NoChangeNeeded'])\n",
    "            else:\n",
    "                y.append(no_diff)\n",
    "        else:\n",
    "            y.append(no_diff)\n",
    "    \n",
    "    #1 means there is no change and 0 means there is a change\n",
    "    df = pd.DataFrame(searchArrays)\n",
    "    df = pd.concat([df, pd.get_dummies(df['consultant'], prefix='consultant')], axis=1)\n",
    "    \n",
    "   \n",
    "    #need to do this because some of the older searchArray had times as a string hh:mm\n",
    "    if 'uiFallAsleepTyp' in df:\n",
    "        df['uiFallAsleepTyp'] = df['uiFallAsleepTyp'].apply(time_convert)\n",
    "    if 'uiWakeUpTyp' in df:\n",
    "        df['uiWakeUpTyp'] = df['uiWakeUpTyp'].apply(time_convert)\n",
    "\n",
    "    return df, np.array(y), sleep_training, anything_else\n",
    "\n",
    "consultants = assignee_to_name.values()\n",
    "#ignoring Jolan and Juliet since they change everytthing\n",
    "consultants = [c for c in consultants if c not in ['Marko', 'Timm', 'Daniel', 'DH_test', 'Robert', 'Allan', 'Alejandra', 'Sophia', 'Seng BSS', 'Meg']]\n",
    "consultants.append('nobody')\n",
    "rec_req_free_txt = get_rec_requests()\n",
    "X, y, sleep_training, anything_else = GetTrainingData(rec_req_free_txt, compare_triage_list1, \n",
    "                                                      req_key_to_triage, triage_features, \n",
    "                                                      consultants, useConsultantAnswerForChange=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def xgb_using_cv(x_train, y_train, param_comb=100):\n",
    "    clf_xg = XGBClassifier(learning_rate=0.025, n_estimators=100, \n",
    "                           objective='binary:logistic', \n",
    "                           batchseed=0, nthread=1)\n",
    "    params = {\n",
    "        'min_child_weight': [1, 2.0, 3.0],\n",
    "        'gamma': [0, 1, 2.5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [1, 2, 3],\n",
    "        'colsample_bytree': [0.4, 0.6, 0.8],\n",
    "        'scale_pos_weight': [2, 3, 4]\n",
    "        }\n",
    "\n",
    "    folds = 4\n",
    "   \n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 0)\n",
    "\n",
    "    random_search = RandomizedSearchCV(clf_xg, param_distributions=params, n_iter=param_comb, \n",
    "                                       scoring='precision', n_jobs=4, cv=skf.split(x_train, y_train), \n",
    "                                       verbose=3, random_state=0)\n",
    "    random_search.fit(x_train, y_train)\n",
    "    print(random_search.best_params_)\n",
    "    #now we fit the classifier on the training data\n",
    "    clf_xg.set_params(**random_search.best_params_)\n",
    "    clf_xg.set_params(nthread=4)\n",
    "    clf_xg.fit(x_train, y_train)\n",
    "    return clf_xg\n",
    "\n",
    "def xgb_test(clf_xg, x_test, y_test):\n",
    "    y_predict_test = clf_xg.predict(x_test)\n",
    "    \n",
    "    print(confusion_matrix(y_test, y_predict_test))\n",
    "    y_predict_score = clf_xg.predict_proba(x_test)[:,1]\n",
    "    fpr, tpr, thresh = roc_curve(y_test, y_predict_score)\n",
    "    return fpr, tpr, y_predict_score\n",
    "\n",
    "\n",
    "def clean_data(X, y, consultants):\n",
    "    df1 = X.fillna(-5)\n",
    "\n",
    "    for c in df1.columns:\n",
    "        if 'free_text' in c or 'night_start_mis' in c or 'sleep_training' in c:\n",
    "            continue\n",
    "        if 'diffSection' in c: \n",
    "            df1 = df1.drop(columns=c)\n",
    "        if 'consultant_' in c:\n",
    "            consultant = c.split('_')[1]\n",
    "            if consultants and consultant not in consultants:\n",
    "                df1 = df1.drop(columns=c)\n",
    "            if not consultants:\n",
    "                df1 = df1.drop(columns=c)\n",
    "            \n",
    "    if consultants:\n",
    "        consultant_indices = df1['consultant'].isin(consultants)\n",
    "        df1 = df1[consultant_indices]\n",
    "        y2 = y[consultant_indices]\n",
    "    else:\n",
    "        y2 = y\n",
    "    \n",
    "    if 'consultant' in df1.columns:\n",
    "        df1 = df1.drop(columns='consultant')\n",
    "    df1 = df1.apply(pd.to_numeric)\n",
    "    \n",
    "    return df1, y2\n",
    "\n",
    "\n",
    "def split_data(X, y, use_random=True):\n",
    "    #np.random.seed(10)\n",
    "    np.random.seed(20)\n",
    "    if use_random:\n",
    "        mask = np.random.rand(len(X)) < 0.6\n",
    "    else:\n",
    "        mask = np.arange(0, len(X)) < 0.8*len(X)\n",
    "    \n",
    "    X_train, y_train = X[mask], y[mask]\n",
    "    X_test, y_test = X[~mask], y[~mask]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def ROC_All(X1, y1, params, consultants=[], random_split=True):\n",
    "    X, y = clean_data(X1, y1, consultants)\n",
    "    X_train, y_train, X_test, y_test = split_data(X, y, random_split)\n",
    "    if params:\n",
    "        clf_xg = XGBClassifier(learning_rate=0.05, n_estimators=1600, \n",
    "                           objective='binary:logistic', seed=0, nthread=8)\n",
    "        clf_xg.set_params(**params)\n",
    "        clf_xg.fit(X_train, y_train)\n",
    "    else:\n",
    "        clf_xg = xgb_using_cv(X_train, y_train, 100)\n",
    "    fpr_all, tpr_all, y_pred_score = xgb_test(clf_xg, X_test, y_test)\n",
    "    \n",
    "    #do the fpr, tpr for different consultants\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr_all, tpr_all, label='consultant_feature')\n",
    "    ax.plot([0, 1], [0, 1])\n",
    "    \n",
    "    return clf_xg, fpr_all, tpr_all, X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ageMagIndex</th>\n",
       "      <th>analysisType</th>\n",
       "      <th>anything_else</th>\n",
       "      <th>bedTimeRoutineLength</th>\n",
       "      <th>birthday</th>\n",
       "      <th>calc_age</th>\n",
       "      <th>catBedTimeOffCONT</th>\n",
       "      <th>catBedtimeNotConsistent</th>\n",
       "      <th>catBedtimeUnconventional</th>\n",
       "      <th>...</th>\n",
       "      <th>consultant_Amy</th>\n",
       "      <th>consultant_AmyB</th>\n",
       "      <th>consultant_Beth</th>\n",
       "      <th>consultant_Cindy</th>\n",
       "      <th>consultant_Daniella</th>\n",
       "      <th>consultant_Eileen</th>\n",
       "      <th>consultant_Janelle</th>\n",
       "      <th>consultant_Jen</th>\n",
       "      <th>consultant_Jolan</th>\n",
       "      <th>consultant_Juliet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Judah is very attached to his soother when it ...</td>\n",
       "      <td>2700</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>461.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2700</td>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>2</td>\n",
       "      <td>8100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Newborn</td>\n",
       "      <td>1800</td>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>0</td>\n",
       "      <td>-11700.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>He loves sleeping on his stomach but we do und...</td>\n",
       "      <td>2700</td>\n",
       "      <td>2021-07-17</td>\n",
       "      <td>1</td>\n",
       "      <td>-1800.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Work in office and remotely \\nMultiple caregiv...</td>\n",
       "      <td>2700</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>3</td>\n",
       "      <td>4904.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1800</td>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>2</td>\n",
       "      <td>6581.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1431</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Dad works out of town M-F and is home on the w...</td>\n",
       "      <td>1800</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>3</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1432</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1800</td>\n",
       "      <td>2021-05-04</td>\n",
       "      <td>2</td>\n",
       "      <td>723.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1433</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2700</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>1</td>\n",
       "      <td>-4651.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1434</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1800</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>2</td>\n",
       "      <td>3116.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1435 rows  380 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  ageMagIndex  analysisType  \\\n",
       "0       4            3             0   \n",
       "1       2            1             0   \n",
       "2       0            0             0   \n",
       "3       1            0             0   \n",
       "4       3            2             0   \n",
       "...   ...          ...           ...   \n",
       "1430    2            1             0   \n",
       "1431    3            2             0   \n",
       "1432    2            1             0   \n",
       "1433    1            0             0   \n",
       "1434    2            1             0   \n",
       "\n",
       "                                          anything_else  bedTimeRoutineLength  \\\n",
       "0     Judah is very attached to his soother when it ...                  2700   \n",
       "1                                                   NaN                  2700   \n",
       "2                                               Newborn                  1800   \n",
       "3     He loves sleeping on his stomach but we do und...                  2700   \n",
       "4     Work in office and remotely \\nMultiple caregiv...                  2700   \n",
       "...                                                 ...                   ...   \n",
       "1430                                                NaN                  1800   \n",
       "1431  Dad works out of town M-F and is home on the w...                  1800   \n",
       "1432                                                NaN                  1800   \n",
       "1433                                                NaN                  2700   \n",
       "1434                                                NaN                  1800   \n",
       "\n",
       "        birthday  calc_age  catBedTimeOffCONT  catBedtimeNotConsistent  \\\n",
       "0     2021-04-01         4         461.500000                        1   \n",
       "1     2021-07-06         2        8100.000000                        0   \n",
       "2     2021-08-27         0      -11700.000000                        0   \n",
       "3     2021-07-17         1       -1800.000000                        0   \n",
       "4     2021-05-28         3        4904.250000                        1   \n",
       "...          ...       ...                ...                      ...   \n",
       "1430  2021-05-07         2        6581.500000                        1   \n",
       "1431  2021-04-14         3         105.000000                        0   \n",
       "1432  2021-05-04         2         723.714286                        0   \n",
       "1433  2021-06-04         1       -4651.666667                        1   \n",
       "1434  2021-05-05         2        3116.333333                        1   \n",
       "\n",
       "      catBedtimeUnconventional  ...  consultant_Amy  consultant_AmyB  \\\n",
       "0                            0  ...               0                0   \n",
       "1                            1  ...               0                0   \n",
       "2                            0  ...               0                0   \n",
       "3                            0  ...               0                0   \n",
       "4                            1  ...               0                0   \n",
       "...                        ...  ...             ...              ...   \n",
       "1430                         1  ...               0                0   \n",
       "1431                         0  ...               0                0   \n",
       "1432                         0  ...               0                0   \n",
       "1433                         0  ...               0                0   \n",
       "1434                         0  ...               0                0   \n",
       "\n",
       "      consultant_Beth  consultant_Cindy  consultant_Daniella  \\\n",
       "0                   0                 0                    0   \n",
       "1                   0                 0                    0   \n",
       "2                   0                 0                    0   \n",
       "3                   0                 0                    0   \n",
       "4                   0                 0                    0   \n",
       "...               ...               ...                  ...   \n",
       "1430                0                 0                    1   \n",
       "1431                0                 1                    0   \n",
       "1432                0                 1                    0   \n",
       "1433                0                 1                    0   \n",
       "1434                0                 1                    0   \n",
       "\n",
       "      consultant_Eileen  consultant_Janelle  consultant_Jen  consultant_Jolan  \\\n",
       "0                     0                   0               0                 1   \n",
       "1                     0                   0               0                 1   \n",
       "2                     0                   0               0                 1   \n",
       "3                     0                   0               0                 1   \n",
       "4                     0                   0               0                 1   \n",
       "...                 ...                 ...             ...               ...   \n",
       "1430                  0                   0               0                 0   \n",
       "1431                  0                   0               0                 0   \n",
       "1432                  0                   0               0                 0   \n",
       "1433                  0                   0               0                 0   \n",
       "1434                  0                   0               0                 0   \n",
       "\n",
       "      consultant_Juliet  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "1430                  0  \n",
       "1431                  0  \n",
       "1432                  0  \n",
       "1433                  0  \n",
       "1434                  0  \n",
       "\n",
       "[1435 rows x 380 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_sections = []\n",
    "for c in X.columns:\n",
    "    if 'diffSection_' in c:\n",
    "        diff_sections.append(c)\n",
    "        X[c].fillna(1, inplace=True)\n",
    "\n",
    "diff_sections = [c for c in diff_sections if ('div' not in c and 'optional' not in c.lower())]\n",
    "diff_sections = [c for c in diff_sections if 'recommended schedule' not in c.lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in X.columns:\n",
    "    if 'diffSection_' in c and ('rescue' in c.lower() or '5AM' in c.lower() or '5 AM' in c.lower()):\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['consultant'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns which does not make sense to use especially since some are missing\n",
    "#age maybe important since premature weeks can affect the recommendations\n",
    "#parTotalDaysleepAvg - some missing data, for now we will not put it in\n",
    "\n",
    "columns_to_drop = ['age', 'gender', 'ageMagIndex', 'analysisType', 'parAgeRoundUp', \n",
    "                   'recTotalSleepforCustom', 'recTotalSleepforSched', \n",
    "                   'recTotalSleepforEoS', 'other_ans',\n",
    "                   'uiEarliestDinner', 'dinner_time',\n",
    "                   '28903230_other', '28903229_other', 'sched_morning_relaxed', 'sched_morning_relaxed_OK',\n",
    "                   'sched_next_ageGroup', 'sched_night_relaxed',\n",
    "                   'sched_night_relaxed_OK', 'sched_shorten_naps']\n",
    "\n",
    "# columns_to_drop = ['age', 'ageMagIndex', 'analysisType', 'parAgeRoundUp', \n",
    "#                    'recTotalSleepforCustom', 'recTotalSleepforSched',\n",
    "#                    'recTotalSleepforEoS', 'other_ans', 'bedTimeRoutineLength',\n",
    "#                    'uiDesiredWakeup', 'recWakeUpTime', 'free_text', 'earliest_getready_bedtime',\n",
    "#                    'uiEarliestDinner', 'earliestGetforBedtime', 'earliest_dinner', 'dinner_time', 'recNightStartTime',\n",
    "#                    '28903230_other', '28903229_other', 'sched_morning_relaxed', 'sched_morning_relaxed_OK',\n",
    "#        'sched_next_ageGroup', 'sched_night_relaxed',\n",
    "#        'sched_night_relaxed_OK', 'sched_shorten_naps']\n",
    "\n",
    "tmp = ['uiAlsoWhileHeldtoSleep', 'parTotalDaySleepAVG', 'num_recs', 'uiAlsoStrollertoSleep',]\n",
    "#for each one of these groups, we will add a new label of -5 for not answering. one hot encoding and potentially\n",
    "#that embedding stuff\n",
    "ui_group = [['uiOnlyBreastFeedtoSleep', 'uiAlsoSlingtoSleep', 'uiAlsoOwnSpaceHandOnChildtoSleep', \n",
    "             'uiAlsoParentNextNotTouchingtoSleep'],\n",
    "            \n",
    "            ['uiHappyPleasantAfterNaps', 'uiTiredCrankyAfterNaps', 'uiAngryinPainAfterNaps', \n",
    "             'uiMoodVariesAfterNaps'],\n",
    "            \n",
    "            ['uiNoNightWaking', 'uiHungryNightWaking', 'uiWantsComfortingNightWaking', \n",
    "             'uiNightmareNightWaking', 'uiNightTerrorNightWaking', 'uiDiaperLeakNightWaking', \n",
    "             'uiPoopyDiaperNightWaking', 'uiUseToiletNightWaking', 'uiPlayPracticeSkillsNightWaking', \n",
    "             'uiWantstoGotoParentsNightWaking', 'uiItchyNightWaking', 'uiGasWindNightWaking', \n",
    "             'uiBlanketOffNightWaking', 'uiEnvironmentNightWaking', 'uiTeethingNightWaking'],\n",
    "            \n",
    "            ['napsameasnight', 'uiFallsAsleepUnassistedNap', 'uiInMotionNap', 'uiBreastFeedNap', \n",
    "             'uiBottleFeedNap', 'uiSlingNap', 'uiTransfertoBedNap', 'uiWatchTVNap', \n",
    "             'uiParentNextTouchingNap', 'uiParentNextNotTouchingNap', 'uiPacifierNap', \n",
    "             'uiComfortItemNap', 'uiSwingNap', 'uiSwaddledNap', 'uiLyingOnSomeoneNap', 'uiTransfertoBedNap'],\n",
    "            \n",
    "            ['uiFallsAsleepUnassistedBedTime', 'uiBreastFeedBedTime', 'uiSlingBedTime', 'uiInMotionBedTime', \n",
    "             'uiTransfertoBedBedTime', 'uiParentNextTouchingBedTime', 'uiParentNextNotTouchingBedTime', \n",
    "             'uiBottleFeedBedTime', 'uiPacifierBedTime', 'uiComfortItemBedTime', 'uiWatchTVBedTime', \n",
    "             'uiOwnSpaceHandOnChildBedTime', 'uiSwingBedTime', 'uiSwaddledBedTime', 'uiTransfertoBedBedTime'],\n",
    "            \n",
    "            ['uiCaredforByParentsDay', 'uiCaredforinNurseryDay', 'uiHomeNoParentsDay', 'uiVariesDayTimeCare'],\n",
    "            \n",
    "            ['uiTiredClingyBeforeNightSleep', 'uiEnergeticButTired1HrBeforeNightSleep', \n",
    "             'uiEnergeticBeforeNightSleep', 'uiHappyPleasantBeforeNightSleep'],\n",
    "\n",
    "            ['uiWantstoGotoParentsNightWaking', 'uiItchyNightWaking', 'uiGasWindNightWaking', \n",
    "             'uiBlanketOffNightWaking', 'uiEnvironmentNightWaking', 'uiTeethingNightWaking'],\n",
    "            \n",
    "            ['uiHappyPleasantAfterMorningPlus1Hr', 'uiHappyPleasantAfterMorningTiredIn1Hr', \n",
    "             'uiTiredCrankyAfterMorning', 'uiMoodVariesAfterMorning'],\n",
    "            \n",
    "            ['uiMedicalNone', 'uiMedicalReflux', 'uiMedicalEczema', 'uiMedicalAsthma', 'uiMedicalSnoring', \n",
    "             'uiMedicalASD', 'uiMedicalADHD', 'uiMedicalSPDorAPD', 'uiMedicalNoDisclose', 'uiMedicalSweating'],\n",
    "            \n",
    "            ['uiOwnRoomOwnBedNight', 'uiSharedRoomOwnBedNight', 'uiParentRoomOwnBedNight', 'uiCoSleepNight', \n",
    "             'uiStartinOwnBedEndwithParentsNight'],\n",
    "            \n",
    "            ['uiPriorityNightWakings', 'uiPriorityNaps', 'uiPrioritySleepIn', 'uiPriorityEasierBedtime', \n",
    "             'uiPriorityCoSleeping', 'uiPrioritySchedule', 'uiPriorityNone'],\n",
    "           ]\n",
    "\n",
    "#these have multiple values and if we want to use one-hot encoding, need to add in multiple versions\n",
    "ui_expand = ['uiContinueCoSleepNB', 'uiContinueShareRoomNB', 'uiRecentSleepIssueNB', \n",
    "             'uiSleepRoutineNB', 'uiStrangeSituationCryNB']\n",
    "\n",
    "\n",
    "\n",
    "#again we need a -5 for this, but most of the values is mostly -5 (no answers)\n",
    "ui_skip = [\n",
    "           ['uiCaredforByParentsDayMon', 'uiCaredforinNurseryDayMon', 'uiHomeNoParentsDayMon', \n",
    "            'uiCaredforByParentsDayTue', 'uiCaredforinNurseryDayTue', 'uiHomeNoParentsDayTue', \n",
    "            'uiCaredforByParentsDayWed', 'uiCaredforinNurseryDayWed', 'uiHomeNoParentsDayWed', \n",
    "            'uiCaredforByParentsDayThu', 'uiCaredforinNurseryDayThu', 'uiHomeNoParentsDayThu', \n",
    "            'uiCaredforByParentsDayFri', 'uiCaredforinNurseryDayFri', 'uiHomeNoParentsDayFri'],\n",
    "\n",
    "           \n",
    "           ['uiFlexibleNapsDaycareNB'],\n",
    "           \n",
    "           ['uiResistsBedtime'],\n",
    "           \n",
    "           ['uiSharingNighDutiesNB'],\n",
    "           \n",
    "           ['uiTransfertoBedBedTime']\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedTimeRoutineLength</th>\n",
       "      <th>calc_age</th>\n",
       "      <th>catBedTimeOffCONT</th>\n",
       "      <th>catBedtimeNotConsistent</th>\n",
       "      <th>catBedtimeUnconventional</th>\n",
       "      <th>catCannotSelfSettle</th>\n",
       "      <th>catDesiredWakeUp1HrEarlier</th>\n",
       "      <th>catDesiredWakeUpVTypWakeup</th>\n",
       "      <th>catDinnerTimeTooLate</th>\n",
       "      <th>catExclusivelyBottleFed</th>\n",
       "      <th>...</th>\n",
       "      <th>consultant_Amy</th>\n",
       "      <th>consultant_AmyB</th>\n",
       "      <th>consultant_Beth</th>\n",
       "      <th>consultant_Cindy</th>\n",
       "      <th>consultant_Daniella</th>\n",
       "      <th>consultant_Eileen</th>\n",
       "      <th>consultant_Janelle</th>\n",
       "      <th>consultant_Jen</th>\n",
       "      <th>consultant_Jolan</th>\n",
       "      <th>consultant_Juliet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2700</td>\n",
       "      <td>4</td>\n",
       "      <td>461.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2700</td>\n",
       "      <td>2</td>\n",
       "      <td>8100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>-11700.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2700</td>\n",
       "      <td>1</td>\n",
       "      <td>-1800.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2700</td>\n",
       "      <td>3</td>\n",
       "      <td>4904.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>1800</td>\n",
       "      <td>2</td>\n",
       "      <td>6581.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1431</td>\n",
       "      <td>1800</td>\n",
       "      <td>3</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1432</td>\n",
       "      <td>1800</td>\n",
       "      <td>2</td>\n",
       "      <td>723.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1433</td>\n",
       "      <td>2700</td>\n",
       "      <td>1</td>\n",
       "      <td>-4651.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1434</td>\n",
       "      <td>1800</td>\n",
       "      <td>2</td>\n",
       "      <td>3116.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1435 rows  314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bedTimeRoutineLength  calc_age  catBedTimeOffCONT  \\\n",
       "0                     2700         4         461.500000   \n",
       "1                     2700         2        8100.000000   \n",
       "2                     1800         0      -11700.000000   \n",
       "3                     2700         1       -1800.000000   \n",
       "4                     2700         3        4904.250000   \n",
       "...                    ...       ...                ...   \n",
       "1430                  1800         2        6581.500000   \n",
       "1431                  1800         3         105.000000   \n",
       "1432                  1800         2         723.714286   \n",
       "1433                  2700         1       -4651.666667   \n",
       "1434                  1800         2        3116.333333   \n",
       "\n",
       "      catBedtimeNotConsistent  catBedtimeUnconventional  catCannotSelfSettle  \\\n",
       "0                           1                         0                    0   \n",
       "1                           0                         1                    0   \n",
       "2                           0                         0                    0   \n",
       "3                           0                         0                    0   \n",
       "4                           1                         1                    1   \n",
       "...                       ...                       ...                  ...   \n",
       "1430                        1                         1                    0   \n",
       "1431                        0                         0                    1   \n",
       "1432                        0                         0                    0   \n",
       "1433                        1                         0                    0   \n",
       "1434                        1                         0                    0   \n",
       "\n",
       "      catDesiredWakeUp1HrEarlier  catDesiredWakeUpVTypWakeup  \\\n",
       "0                              0                           1   \n",
       "1                              0                           1   \n",
       "2                              0                           0   \n",
       "3                              0                           1   \n",
       "4                              0                          -1   \n",
       "...                          ...                         ...   \n",
       "1430                           0                          -1   \n",
       "1431                           0                          -1   \n",
       "1432                           0                           1   \n",
       "1433                           0                          -1   \n",
       "1434                           1                          -1   \n",
       "\n",
       "      catDinnerTimeTooLate  catExclusivelyBottleFed  ...  consultant_Amy  \\\n",
       "0                        0                        0  ...               0   \n",
       "1                        0                        0  ...               0   \n",
       "2                        0                        0  ...               0   \n",
       "3                        0                        0  ...               0   \n",
       "4                        0                        0  ...               0   \n",
       "...                    ...                      ...  ...             ...   \n",
       "1430                     0                        0  ...               0   \n",
       "1431                     0                        0  ...               0   \n",
       "1432                     0                        0  ...               0   \n",
       "1433                     0                        0  ...               0   \n",
       "1434                     0                        0  ...               0   \n",
       "\n",
       "      consultant_AmyB  consultant_Beth  consultant_Cindy  consultant_Daniella  \\\n",
       "0                   0                0                 0                    0   \n",
       "1                   0                0                 0                    0   \n",
       "2                   0                0                 0                    0   \n",
       "3                   0                0                 0                    0   \n",
       "4                   0                0                 0                    0   \n",
       "...               ...              ...               ...                  ...   \n",
       "1430                0                0                 0                    1   \n",
       "1431                0                0                 1                    0   \n",
       "1432                0                0                 1                    0   \n",
       "1433                0                0                 1                    0   \n",
       "1434                0                0                 1                    0   \n",
       "\n",
       "      consultant_Eileen  consultant_Janelle  consultant_Jen  consultant_Jolan  \\\n",
       "0                     0                   0               0                 1   \n",
       "1                     0                   0               0                 1   \n",
       "2                     0                   0               0                 1   \n",
       "3                     0                   0               0                 1   \n",
       "4                     0                   0               0                 1   \n",
       "...                 ...                 ...             ...               ...   \n",
       "1430                  0                   0               0                 0   \n",
       "1431                  0                   0               0                 0   \n",
       "1432                  0                   0               0                 0   \n",
       "1433                  0                   0               0                 0   \n",
       "1434                  0                   0               0                 0   \n",
       "\n",
       "      consultant_Juliet  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "1430                  0  \n",
       "1431                  0  \n",
       "1432                  0  \n",
       "1433                  0  \n",
       "1434                  0  \n",
       "\n",
       "[1435 rows x 314 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in ui_skip:\n",
    "    columns_to_drop.extend(c)\n",
    "\n",
    "# for c in X.columns:\n",
    "#     if c.startswith('par'):\n",
    "#         columns_to_drop.append(c)\n",
    "\n",
    "columns_to_drop.extend(['birthday', 'child_name', 'desired_wakeup', 'dinner_time', 'earliest_getready_bedtime', \n",
    "                        'getready_bedtime', 'mhour', 'nhour', 'time_zone', 'uid', 'cid', 'req_key', 'email', 'child',\n",
    "                        'Birthday', 'sibling_ages', 'sibling_age', 'date_submit', '28903232_other', \n",
    "                        'anything_else_length', 'other_len', 'dec_age', 'ssAdjust'])\n",
    "\n",
    "\n",
    "par_skip = ['parNumDaysSelected']\n",
    "\n",
    "columns_to_drop.extend(par_skip)\n",
    "\n",
    "# columns_to_drop.extend(['birthday', 'child_name', 'desired_wakeup', 'dinner_time', 'earliest_getready_bedtime', \n",
    "#                         'getready_bedtime', 'mhour', 'nhour', 'time_zone', 'uid', 'cid', 'req_key', 'email', 'child', 'catBedTimeOffCONT',\n",
    "#                         'dec_age', 'nrecs', 'nweeks', 'Birthday', 'sibling_ages', 'sibling_age', 'date_submit', '28903232_other'])\n",
    "\n",
    "X1 = X\n",
    "for c in columns_to_drop:\n",
    "    if c in X1.columns:\n",
    "        X1 = X1.drop(columns=c)\n",
    "\n",
    "for c in X1.columns:\n",
    "    if '_other' in c:\n",
    "        X1 = X1.drop(columns=c)\n",
    "        \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "X1 = X1.drop(columns=['anything_else', 'slee_training'])\n",
    "\n",
    "X1['bad_schedule'] = X1['bad_schedule']*1\n",
    "X1['has_warning'] = X1['has_warning']*1\n",
    "X1.fillna(-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only important features but it doesnt work\n",
    "important_columns = ['uiHoldRockDuringNightWaking', 'uiMedicalAsthma',\n",
    "       'uiMedicalDisclaimerAgreed', 'uiMedicalEczema', 'uiMedicalNoDisclose',\n",
    "       'uiMedicalSPDorAPD', 'uiMedicalSnoring', 'uiMedicalTongueLipTie',\n",
    "       'uiNightTerrorNightWaking', 'uiNightmareNightWaking',\n",
    "       'uiOnlyBreastFeedtoSleep', 'uiOtherSiblings', 'uiOwnRoomOwnBedNight',\n",
    "       'uiOwnSpaceHandOnChildBedTime', 'uiOwnSpaceHandOnChildNap',\n",
    "       'uiPacifierNap', 'uiParentNextNotTouchingBedTime',\n",
    "       'uiParentNextTouchingBedTime', 'uiMedicalAllergies',\n",
    "       'uiParentsSleepwithChildDuringNightWaking', 'uiMedicalASD',\n",
    "       'uiItchyNightWaking', 'uiContinueCoSleepNB', 'uiDiaperLeakNightWaking',\n",
    "       'uiDinnerTime', 'uiDrinksfromCup', 'uiEnergeticBeforeNightSleep',\n",
    "       'uiEnvironmentNightWaking', 'uiFallsAsleepUnassistedNap',\n",
    "       'uiFallsBackAsleepDuringNightWaking', 'uiGiveWaterDuringNightWaking',\n",
    "       'uiGoestoParentsDuringNightWaking', 'uiHappyPleasantAfterNaps',\n",
    "       'useDesired', 'uiHomeNoParentsDay', 'uiHungryNightWaking',\n",
    "       'uiInMotionBassinetBedTime', 'uiInMotionBassinetNap',\n",
    "       'uiInMotionBedTime', 'uiLyingOnSomeoneNap']\n",
    "\n",
    "X_important = X1[important_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['email']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'consultant' in X1.columns:\n",
    "    X2 = X1.drop(columns='consultant')\n",
    "else:\n",
    "    X2 = X1\n",
    "for c in X2.columns:\n",
    "    if 'consultant_' in c:\n",
    "        X2 = X2.drop(columns=c)\n",
    "    if 'diffSection_' in c:\n",
    "        X2 = X2.drop(columns=c)\n",
    "\n",
    "if 'bad_schedule' in X2.columns:\n",
    "    X2['bad_schedule'] = X2['bad_schedule']*1\n",
    "if 'has_warning' in X2.columns:\n",
    "    X2['has_warning'] = X2['has_warning']*1\n",
    "X2 = X2.fillna(-5)\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "dist = pdist(X2.values, metric='correlation')\n",
    "X2_dist = squareform(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_dist\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(X2_dist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X3 = X2[['uiFallsAsleepUnassistedBedTime', 'uiNightWakingsNB', 'nrecs', 'nweeks', 'nw_number', 'bad_schedule', 'has_warning']]\n",
    "X3 = X[['uiFallsAsleepUnassistedBedTime', 'uiNightWakingsNB', 'nrecs', 'nweeks', 'nw_number', 'has_warning']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (X['has_warning']) | (X['bad_schedule'])\n",
    "y1 = y.copy()\n",
    "y1[idx] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_consultant = (X1['consultant'].isin(['Amy', 'Daniella', 'Kristal', 'Eileen', 'Liz', 'Jessica', 'Heather', 'Jen', 'Amber']))\n",
    "X_good = X[idx_consultant]\n",
    "y1_good = y1[idx_consultant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = X_good\n",
    "pd.options.display.max_colwidth = 100\n",
    "X4['output'] = y1_good\n",
    "X4.loc[(~X4['anything_else'].isnull()) & (X4['output'] == 1), ['anything_else','output', 'email']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_change = (y1_good == 0)\n",
    "zero_words = X_good['nw_number'] == 0\n",
    "no_warnings = (X_good['has_warning'] == 0) & (X_good['bad_schedule']==0)\n",
    "pd.set_option(\"display.min_rows\", 20)\n",
    "\n",
    "for diff_sec in diff_sections:\n",
    "    total_change_sec = sum(idx_change&zero_words&no_warnings) - sum(X_good[idx_change&zero_words&no_warnings][diff_sec])\n",
    "    if total_change_sec > 20:\n",
    "        print(diff_sec, total_change_sec)\n",
    "        sec_change = X_good[diff_sec] == 0\n",
    "        final_idx = (sec_change & idx_change) & zero_words & no_warnings\n",
    "        print(X_good[final_idx][['cid', 'consultant']])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in X1['consultant'].unique():\n",
    "    c_idx = X1['consultant'] == c\n",
    "    print(c, sum(y1[c_idx]), len(y1[c_idx]), sum(y1[c_idx])/len(y1[c_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#params = {'subsample': 0.8, 'scale_pos_weight': 1.75, 'min_child_weight': 1, 'max_depth': 12, 'gamma': 8, 'colsample_bytree': 1.0}\n",
    "#params = {'subsample': 0.8, 'scale_pos_weight': 1.75, 'min_child_weight': 1, 'max_depth': 10, 'gamma': 5}\n",
    "params = {'subsample': 1.0, 'scale_pos_weight': 2.5, 'min_child_weight': 1, 'max_depth': 6, 'gamma': 5}\n",
    "parasm = {'subsample': 1.0, 'scale_pos_weight': 1, 'min_child_weight': 3.0, 'max_depth': 6, 'gamma': 5}\n",
    "#params = {}\n",
    "clf_xg_con3, fpr_all_con3, tpr_all_con3, X_train_tmp1, y_train_tmp1, X_test, y_test = ROC_All(X3, y1, params, [], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_all, tpr_all, y_pred_score = xgb_test(clf_xg_con2_all, X_train2_all, y_train2_all)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr_all, tpr_all, label='updated model')\n",
    "ax.plot([0, 1], [0, 1])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = clf_xg_con2_all.feature_importances_.argsort()\n",
    "X2.columns[sorted_idx][:40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#params = {'subsample': 1.0, 'scale_pos_weight': 2.5, 'min_child_weight': 2, 'max_depth': 5, 'gamma': 5}\n",
    "#params = {'subsample': 1.0, 'scale_pos_weight': 1.35, 'min_child_weight': 1, 'max_depth': 6, 'gamma': 5}\n",
    "params = {'subsample': 0.6, 'scale_pos_weight': 1, 'min_child_weight': 2.0, 'max_depth': 5, 'gamma': 5}\n",
    "params = {'subsample': 0.8, 'scale_pos_weight': 2, 'min_child_weight': 1, 'max_depth': 3, 'gamma': 0, 'colsample_bytree': 0.4}\n",
    "\n",
    "#X2_sub = X2[important]\n",
    "clf_xg_con2_all, fpr_all_con2_all, tpr_all_con2_all, X_train2_all, y_train2_all, X_test2_all, y_test2_all = ROC_All(X2, y1, params, [], True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do testing against the current model\n",
    "import pickle\n",
    "model = pickle.load(open(\"angular_portal/xgb/NEWBORN_EXP.bin\", \"rb\"))\n",
    "\n",
    "def test(model, X_test, y_test):\n",
    "    model_columns = model._Booster.feature_names\n",
    "    print(model_columns)\n",
    "    X_df = X_test.copy()\n",
    "    X_df_columns = set(X_df.columns)\n",
    "    for c in model_columns:\n",
    "        if c not in X_df_columns:\n",
    "            X_df[c] = -5\n",
    "    \n",
    "    if 'gender' in X_df_columns:\n",
    "        X_df['gender_encode'] = 0\n",
    "        X_df.loc[X_df['gender'] == 'M', 'gender_encode'] = 1\n",
    "        X_df['gender'] = X_df['gender_encode']\n",
    "\n",
    "    X_for_predict = X_df[model_columns]\n",
    "    X_for_predict = X_for_predict.apply(pd.to_numeric)\n",
    "    y_predict_score = model.predict_proba(X_for_predict)[:,1]\n",
    "    y_predict_test = y_predict_score > 0.6\n",
    "    print(confusion_matrix(y_test, y_predict_test))\n",
    "    \n",
    "    fpr, tpr, thresh = roc_curve(y_test, y_predict_score)\n",
    "    return fpr, tpr, y_predict_score\n",
    "\n",
    "\n",
    "fpr_all, tpr_all, y_pred_score = test(model, X2, y1)\n",
    "fp_idx = (y_pred_score > 0.6) & (y1 < 0.5)\n",
    "#do the fpr, tpr for different consultants\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr_all, tpr_all, label='old model')\n",
    "ax.plot(fpr_all_con2_all, tpr_all_con2_all, label='new model')\n",
    "\n",
    "ax.plot([0, 1], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = pickle.load(open(\"NEWBORN_MODEL_JULY27_2021.bin\", \"rb\"))\n",
    "fpr_all_con2_all, tpr_all_con2_all, y_pred_score = test(model2, X2, y1)\n",
    "#do the fpr, tpr for different consultants\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr_all, tpr_all, label='old model')\n",
    "ax.plot(fpr_all_con2_all, tpr_all_con2_all, label='new model')\n",
    "ax.legend()\n",
    "ax.plot([0, 1], [0, 1])\n",
    "\n",
    "fp_idx = (y_pred_score > 0.5) & (y1 < 0.5)\n",
    "X[fp_idx]['email']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25/(25+41), 12/(25+41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = clf_xg_con2_all.predict_proba(X_test2_all)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for idx, (yt, yhat) in enumerate(zip(y_test2_all, v)):\n",
    "    if yt == 0 and yhat < 0.3:\n",
    "        print(idx, yt, yhat)\n",
    "        num += 1\n",
    "        \n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 470\n",
    "print(y_test2_all[loc], v[loc])\n",
    "X_df = X_test2_all.iloc[loc:loc+1, :].copy()\n",
    "print(X.loc[X_df.index[0], ['email', 'consultant']])\n",
    "from eli5 import show_prediction\n",
    "show_prediction(clf_xg_con2_all, X_df, feature_names=X_df.columns.values, show_feature_values=True, targets=[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5 import show_weights\n",
    "show_weights(clf_xg_con2_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'subsample': 0.6, 'scale_pos_weight': 4, 'min_child_weight': 5.0, 'max_depth': 10, 'gamma': 5}\n",
    "\n",
    "clf_xg_con2_all, fpr_all_con2_all, tpr_all_con2_all, _, _, X_test2_all, y_test2_all = ROC_All(X2, y1, params, [], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2_all[v > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2_all.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = X_test2_all[X_test2_all['old_index'] == 173]\n",
    "from eli5 import show_prediction\n",
    "show_prediction(clf_xg_con2_all, X_df, feature_names=X_df.columns.values, show_feature_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf_xg_con2_all, open('MODEL_USING_CONSULTANT_SURVEY.bin', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_all, tpr_all, y_pred_score = xgb_test(clf_xg_con2_all, X_test2_tmp_tf2, y_test2_tmp_tf2)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr_all, tpr_all, label='updated model')\n",
    "ax.plot(fpr_all_con2_tmp_tf2, tpr_all_con2_tmp_tf2, label='trained on just cases with NW <= 6')\n",
    "ax.plot([0, 1], [0, 1])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'subsample': 0.8, 'scale_pos_weight': 2.75, 'min_child_weight': 2.0, 'max_depth': 8, 'gamma': 5}\n",
    "#jen_idx = X1['consultant'] == 'Kristal'\n",
    "#zero_words = (X_good['nw_number'] <= 6) & (X_good['sleep_training_len'] <= 5) & (X_good['other_len'] <= 5)\n",
    "#zero_words = X_good['nw_number'] <= 6;\n",
    "#zero_words = zero_words & (X_good['anything_else'].isnull())\n",
    "#zero_words = (X_good['nw_number'] <= 6) & (X_good['anything_else'].isnull())\n",
    "zero_words = (X_good['nw_number'] <= 6)\n",
    "X2_good = X2[idx_consultant]\n",
    "X1_jen = X2_good[zero_words]\n",
    "y1_jen = y1_good[zero_words]\n",
    "\n",
    "clf_xg_con2_tmp_tf2, fpr_all_con2_tmp_tf2, tpr_all_con2_tmp_tf2, X_train, y_train, X_test2_tmp_tf2, y_test2_tmp_tf2 = ROC_All(X1_jen, y1_jen, params, [], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def diff_linesToWords(text1, text2, delimiter=re.compile('\\n')):\n",
    "    \"\"\"\n",
    "        Split two texts into an array of strings.  Reduce the texts to a string\n",
    "        of hashes where each Unicode character represents one line.\n",
    "\n",
    "        95% of this function code is copied from `diff_linesToChars` on:\n",
    "            https://github.com/google/diff-match-patch/blob/895a9512bbcee0ac5a8ffcee36062c8a79f5dcda/python3/diff_match_patch.py#L381\n",
    "\n",
    "        Copyright 2018 The diff-match-patch Authors.\n",
    "        https://github.com/google/diff-match-patch\n",
    "        Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "        you may not use this file except in compliance with the License.\n",
    "        You may obtain a copy of the License at\n",
    "          http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "        Args:\n",
    "            text1: First string.\n",
    "            text2: Second string.\n",
    "            delimiter: a re.compile() expression for the word delimiter type\n",
    "\n",
    "        Returns:\n",
    "            Three element tuple, containing the encoded text1, the encoded text2 and\n",
    "            the array of unique strings.  The zeroth element of the array of unique\n",
    "            strings is intentionally blank.\n",
    "    \"\"\"\n",
    "    lineArray = []  # e.g. lineArray[4] == \"Hello\\n\"\n",
    "    lineHash = {}   # e.g. lineHash[\"Hello\\n\"] == 4\n",
    "\n",
    "    # \"\\x00\" is a valid character, but various debuggers don't like it.\n",
    "    # So we'll insert a junk entry to avoid generating a null character.\n",
    "    lineArray.append('')\n",
    "\n",
    "    def diff_linesToCharsMunge(text):\n",
    "        \"\"\"Split a text into an array of strings.  Reduce the texts to a string\n",
    "        of hashes where each Unicode character represents one line.\n",
    "        Modifies linearray and linehash through being a closure.\n",
    "        Args:\n",
    "            text: String to encode.\n",
    "        Returns:\n",
    "            Encoded string.\n",
    "        \"\"\"\n",
    "        chars = []\n",
    "        # Walk the text, pulling out a substring for each line.\n",
    "        # text.split('\\n') would would temporarily double our memory footprint.\n",
    "        # Modifying text would create many large strings to garbage collect.\n",
    "        lineStart = 0\n",
    "        lineEnd = -1\n",
    "        while lineEnd < len(text) - 1:\n",
    "            lineEnd = delimiter.search(text, lineStart)\n",
    "\n",
    "            if lineEnd:\n",
    "                lineEnd = lineEnd.start()\n",
    "\n",
    "            else:\n",
    "                lineEnd = len(text) - 1\n",
    "\n",
    "            line = text[lineStart:lineEnd + 1]\n",
    "\n",
    "            if line in lineHash:\n",
    "                chars.append(chr(lineHash[line]))\n",
    "            else:\n",
    "                if len(lineArray) == maxLines:\n",
    "                    # Bail out at 1114111 because chr(1114112) throws.\n",
    "                    line = text[lineStart:]\n",
    "                    lineEnd = len(text)\n",
    "                lineArray.append(line)\n",
    "                lineHash[line] = len(lineArray) - 1\n",
    "                chars.append(chr(len(lineArray) - 1))\n",
    "            lineStart = lineEnd + 1\n",
    "        return \"\".join(chars)\n",
    "\n",
    "    # Allocate 2/3rds of the space for text1, the rest for text2.\n",
    "    maxLines = 666666\n",
    "    chars1 = diff_linesToCharsMunge(text1)\n",
    "    maxLines = 1114111\n",
    "    chars2 = diff_linesToCharsMunge(text2)\n",
    "    return (chars1, chars2, lineArray)\n",
    "    \n",
    "def diff_line(text1, text2):\n",
    "    dmp = diff_match_patch()\n",
    "    a = diff_linesToWords(text1, text2, delimiter=re.compile('[.!?] '))\n",
    "    lineText1 = a[0]\n",
    "    lineText2 = a[1]\n",
    "    lineArray = a[2] # .lineArray;\n",
    "\n",
    "    print(lineArray)\n",
    "    diffs = dmp.diff_main(lineText1, lineText2, True);\n",
    "    print(diffs)\n",
    "    dmp.diff_charsToLines(diffs, lineArray);\n",
    "   \n",
    "    #dmp.diff_cleanupSemantic(diffs)\n",
    "    return diffs\n",
    "\n",
    "def cleanhtml2(raw_html):\n",
    "    soup = BeautifulSoup(raw_html)\n",
    "    for elem in soup.find_all([\"p\", \"div\", \"br\"]):\n",
    "        elem.replace_with(\"\\n\")\n",
    "    text = soup.get_text()\n",
    "    text = '  '.join([a for a in text.split('\\n') if a.strip()])\n",
    "    text = ' '.join([a for a in text.split() if a.strip()])\n",
    "    cleantext = unicodedata.normalize(\"NFKD\", text)\n",
    "    #return ''.join(cleantext.splitlines())\n",
    "    return cleantext\n",
    "    \n",
    "def get_diff(cid, request_key, output, dbrecs):\n",
    "    #get the req_key\n",
    "    added = []\n",
    "    deleted = []\n",
    "    card_replaced = []\n",
    "    added_sentences = defaultdict(list)\n",
    "    deleted_sentences = defaultdict(list)\n",
    "    sentenced_replaced = defaultdict(list)\n",
    "    found_rec = None\n",
    "    for rec_date, rec in dbrecs[cid].items():\n",
    "        if 'rec_signature' not in rec:\n",
    "            continue\n",
    "        if rec['rec_signature']['creation_sig']['request_key'] == request_key:\n",
    "            found_rec = rec\n",
    "            break\n",
    "    if found_rec is None:\n",
    "        return added, deleted, card_replaced, added_sentences, deleted_sentences\n",
    "    \n",
    "    if 'auto_gen' not in found_rec:\n",
    "        return added, deleted, card_replaced, added_sentences, deleted_sentences\n",
    "    source_id = found_rec['auto_gen']['rec_signature']['_id']\n",
    "    for o in output:\n",
    "        if o[0]['description'] and 'div' in o[0]['description']:\n",
    "            continue\n",
    "        if o[1]['description'] and 'div' in o[1]['description']:\n",
    "            continue\n",
    "        \n",
    "        if o[0]['description'] == '':\n",
    "            deleted.append(o[1]['description'])\n",
    "            continue\n",
    "        \n",
    "        #check if source sig is right\n",
    "        skip = False\n",
    "        for card in found_rec['rec_json']:\n",
    "            if card['description'] == o[0]['description'] and card['rec_sig']['source'] == 'custom_scheduler':\n",
    "                skip = True\n",
    "                break\n",
    "            if card['description'] == o[0]['description'] and card['type'] == 'Schedule':\n",
    "                skip = True\n",
    "                break\n",
    "            \n",
    "            if o[1]['description'] == '' and card['description'] == o[0]['description'] and not card['rec_sig']['source'].startswith(source_id):\n",
    "#                 try:\n",
    "                    \n",
    "#                     added.append('+'.join(card['rectag']))                    \n",
    "#                 except:\n",
    "#                     added.append(o[0]['description'])\n",
    "                added.append(o[0]['description'])\n",
    "                skip = True\n",
    "                break\n",
    "            if card['description'] == o[0]['description'] and not card['rec_sig']['source'].startswith(source_id):\n",
    "                skip = True\n",
    "                card_replaced.append(o[0]['description'])\n",
    "                break\n",
    "        if skip:\n",
    "            continue\n",
    "        #check if it is swapped\n",
    "        if (o[2]['add'] + o[2]['sub']) > 50:\n",
    "            text0 = None\n",
    "            text1 = None\n",
    "            for card in found_rec['rec_json']:\n",
    "                if card['description'] == o[0]['description']:\n",
    "                    text0 = card['htmltext']\n",
    "            \n",
    "            for card in found_rec['auto_gen']['rec_json']:\n",
    "                if card['description'] == o[0]['description']:\n",
    "                    text1 = card['text']\n",
    "            \n",
    "            if text0 == None or text1 == None:\n",
    "                continue\n",
    "            \n",
    "            if cid != 'fi6PZbB5MqDf1Ia2r4i4':\n",
    "                continue\n",
    "            text0 = cleanhtml2(text0)\n",
    "            text1 = cleanhtml2(text1)\n",
    "            diffs = diff_line(text1, text0)\n",
    "            if cid == 'fi6PZbB5MqDf1Ia2r4i4':\n",
    "                print(text0)\n",
    "                print(diffs)\n",
    "            for d in diffs:\n",
    "                if d[0] == 1:\n",
    "                    added_sentences[o[0]['description']].append(d[1].strip())\n",
    "                if d[0] == -1:\n",
    "                    deleted_sentences[o[0]['description']].append(d[1].strip())\n",
    "                    \n",
    "    return added, deleted, card_replaced, added_sentences, deleted_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_free_text_idx = (X_good['nw_number'] <= 5) & (X_good['sleep_training_len'] <= 5) & (X_good['anything_else_length'] <= 5) & (X_good['other_len'] == 0)\n",
    "X_good_no_freetxt = X_good.copy() #X_good[no_free_text_idx].copy()\n",
    "X_good_no_freetxt['output'] = y1_good\n",
    "\n",
    "X_good_no_freetxt['section_added'] = ''\n",
    "X_good_no_freetxt['section_deleted'] = ''\n",
    "X_good_no_freetxt['section_replaced'] = ''\n",
    "\n",
    "for idx, r in X_good_no_freetxt[X_good_no_freetxt['output'] == 0].iterrows():\n",
    "    cid = r['cid']\n",
    "    req_key = r['req_key']\n",
    "    output = None\n",
    "    for t in compare_triage_list1:\n",
    "        if not t:\n",
    "            continue\n",
    "        if t['cid'] == cid and t['creation_sig']['request_key'] == req_key:\n",
    "            output = t['output']\n",
    "            break\n",
    "    if output is None:\n",
    "        continue\n",
    "        \n",
    "    added, deleted, card_replaced, added_sentences, deleted_sentences = get_diff(cid, req_key, output, dbrecs)\n",
    "    if added:\n",
    "        if '(optional) wean from the pacifier at sleep times' in '&&'.join([c.strip().lower() for c in added]):\n",
    "            print(idx, r['cid'])\n",
    "        X_good_no_freetxt.at[idx, 'section_added'] = '+'.join([c.strip().lower() for c in added])\n",
    "    if deleted:\n",
    "        X_good_no_freetxt.at[idx, 'section_deleted'] = ','.join([c.strip().lower() for c in deleted])\n",
    "    \n",
    "    if card_replaced:\n",
    "        X_good_no_freetxt.at[idx, 'section_replaced'] = ','.join([c.strip().lower() for c in card_replaced])\n",
    "        \n",
    "    if added_sentences:\n",
    "        for k, v in added_sentences.items():\n",
    "            X_good_no_freetxt.at[idx, 'sentences_add_'+k] = ','.join(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_json = dbrecs['fi6PZbB5MqDf1Ia2r4i4']['1587936774']['rec_json']\n",
    "for card in rec_json:\n",
    "    if card['description'] == 'Explanation of schedule':\n",
    "        break\n",
    "\n",
    "soup = BeautifulSoup(card['htmltext'])\n",
    "for elem in soup.find_all(['p', 'div', 'br']):\n",
    "    elem.replace_with(\"\\n\")\n",
    "    \n",
    "text = soup.get_text()\n",
    "text = '\\n'.join([a for a in text.split('\\n') if a.strip()])\n",
    "text\n",
    "#cleantext = unicodedata.normalize(\"NFKD\", cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_good_no_freetxt[~X_good_no_freetxt['sentences_add_Explanation of schedule'].isnull()][['cid', 'email','sentences_add_Explanation of schedule']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nap_columns = [c for c in X_good_no_freetxt.columns if 'nap' in c.lower() and 'diffSection' not in c]\n",
    "tmp_df2.loc[tmp_df2['faun4+faun20+faun13+faun14+faun19'] == 1, ['consultant', 'cid'] + nap_columns]\n",
    "tmp_df2.loc[tmp_df2['faun4+faun20+faun13+faun14+faun19'] == 1, ['consultant', 'email', 'cid', 'catParentSleepHelpBedTime', 'catNapTimeDurInconsistent', 'catParentSleepHelpNaps']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_good_no_freetxt.loc[2407:2408]['section_added'].str.contains('(optional) wean from the pacifier at sleep times'))\n",
    "sum(X_good_no_freetxt['section_added'].str.lower().str.contains('(optional) wean from the pacifier at sleep times'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = set()\n",
    "for x in X_good_no_freetxt['section_added'].str.split('+').values:\n",
    "    for a in x:\n",
    "        if a == '(optional) wean from the pacifier at sleep times':\n",
    "            print(x)\n",
    "        d.add(a)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in d:\n",
    "    if not a:\n",
    "        continue\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    changed_idx = X_good_no_freetxt['output'] == 0\n",
    "    institute_nap_hour = X_good_no_freetxt['section_added'].str.lower().str.contains(a.lower(), regex=False)\n",
    "    print(a, \":\", sum(institute_nap_hour))\n",
    "    print(\"changed:\", sum(changed_idx), a + \" changed:\", sum(changed_idx & institute_nap_hour))\n",
    "    consultant = True #True | X_good_no_freetxt['consultant'] == 'Liz'\n",
    "    institute_nap_hour = consultant & institute_nap_hour\n",
    "    print(sum(changed_idx & institute_nap_hour))\n",
    "    print(X_good_no_freetxt.loc[(changed_idx & institute_nap_hour) & priority_naps, ['uiCannotStandCrying', 'catShortNaps', 'catParentSleepHelpNaps', 'uiPriorityNaps']].sum())\n",
    "    X_good_no_freetxt.loc[(changed_idx & institute_nap_hour) & priority_naps, ['cid', 'age', 'consultant', 'section_added', 'uiCannotStandCrying', 'catShortNaps', 'catParentSleepHelpNaps', 'uiPriorityNaps']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_idx = X_good_no_freetxt['output'] == 0\n",
    "institute_nap_hour = X_good_no_freetxt['section_added'].str.lower().str.contains(\"middle of the night wakings\", regex=False)\n",
    "print(\"changed:\", sum(changed_idx), \"changed with nap hour:\", sum(changed_idx & institute_nap_hour))\n",
    "consultant = True #True | X_good_no_freetxt['consultant'] == 'Liz'\n",
    "institute_nap_hour = consultant & institute_nap_hour\n",
    "print(sum(changed_idx & institute_nap_hour))\n",
    "print(X_good_no_freetxt.loc[(changed_idx & institute_nap_hour) & priority_naps, ['uiCannotStandCrying', 'catShortNaps', 'catParentSleepHelpNaps', 'uiPriorityNaps']].sum())\n",
    "X_good_no_freetxt.loc[(changed_idx & institute_nap_hour) & priority_naps, ['email', 'cid', 'age', 'consultant', 'section_added', 'catReqNightAssistance', 'catShortNaps', 'catParentSleepHelpNaps', 'uiPriorityNaps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = clf_xg_con2_tmp_tf2.predict_proba(X_test2_tmp_tf2)\n",
    "tmp = (y_test2_tmp_tf2 == 0) & (y_pred[:, 1] > 0.7)\n",
    "idx = X_test2_tmp_tf2[tmp].index\n",
    "X_good1 = X_good.loc[idx]\n",
    "consultant = 'Amy'\n",
    "daniella = X_good1['consultant'] == consultant\n",
    "X_good3 = X_good[X_good['consultant'] == consultant].copy()\n",
    "X_good3['output'] = y1_good[X_good['consultant'] == consultant]\n",
    "print(len(X_good1[daniella]))\n",
    "X_good1[daniella][['email', 'cid', 'uid']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_case = X_test2_tmp_tf2.loc[637]\n",
    "show_prediction(clf_xg_con2_tmp_tf2, tmp_case, feature_names=X_test2_tmp_tf2.columns.values, show_feature_values=True, targets=[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_prediction(clf_xg_con2_tmp_tf2, X_test2_tmp_tf2.iloc[8:9], feature_names=X_test2_tmp_tf2.columns.values, show_feature_values=True, targets=[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'subsample': 1.0, 'scale_pos_weight': 8.5, 'min_child_weight': 3.0, 'max_depth': 6, 'gamma': 5}\n",
    "clf_xg_con2_tmp_tf2, fpr_all_con2_tmp_tf2, tpr_all_con2_tmp_tf2, _, _, X_test2_tmp_tf2, y_test2_tmp_tf2 = ROC_All(X2, y1, params, [], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose a different scorer that increases recall\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=5)\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def xgb_using_cv(x_train, y_train, param_comb=100):\n",
    "    clf_xg = XGBClassifier(learning_rate=0.05, n_estimators=1000, \n",
    "                           objective='binary:logistic', batchseed=0, nthread=1)\n",
    "    params = {\n",
    "        'min_child_weight': [1, 2.0, 3.0],\n",
    "        'gamma': [0, 1, 2.5, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [6, 8, 10, 12],\n",
    "        'scale_pos_weight': [1.5, 2, 2.5, 2.75]\n",
    "        }\n",
    "\n",
    "    folds = 3\n",
    "   \n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 10)\n",
    "\n",
    "    random_search = RandomizedSearchCV(clf_xg, param_distributions=params, n_iter=param_comb, \n",
    "                                       scoring=ftwo_scorer, n_jobs=4, cv=skf.split(x_train, y_train), \n",
    "                                       verbose=3, random_state=0)\n",
    "    random_search.fit(x_train, y_train)\n",
    "    print(random_search.best_params_)\n",
    "    #now we fit the classifier on the training data\n",
    "    clf_xg.set_params(**random_search.best_params_)\n",
    "    clf_xg.set_params(nthread=4)\n",
    "    clf_xg.fit(x_train, y_train)\n",
    "    return clf_xg\n",
    "\n",
    "def xgb_test(clf_xg, x_test, y_test):\n",
    "    y_predict_test = clf_xg.predict(x_test)\n",
    "    \n",
    "    print(confusion_matrix(y_test, y_predict_test))\n",
    "    y_predict_score = clf_xg.predict_proba(x_test)[:,1]\n",
    "    fpr, tpr, thresh = roc_curve(y_test, y_predict_score)\n",
    "    return fpr, tpr, y_predict_score\n",
    "\n",
    "\n",
    "def clean_data(X, y, consultants):\n",
    "    df1 = X.fillna(-5)\n",
    "\n",
    "    for c in df1.columns:\n",
    "        if 'free_text' in c or 'night_start_mis' in c or 'sleep_training' in c:\n",
    "            continue\n",
    "        if 'diffSection' in c: \n",
    "            df1 = df1.drop(columns=c)\n",
    "        if 'consultant_' in c:\n",
    "            consultant = c.split('_')[1]\n",
    "            if consultants and consultant not in consultants:\n",
    "                df1 = df1.drop(columns=c)\n",
    "            if not consultants:\n",
    "                df1 = df1.drop(columns=c)\n",
    "            \n",
    "    if consultants:\n",
    "        consultant_indices = df1['consultant'].isin(consultants)\n",
    "        df1 = df1[consultant_indices]\n",
    "        y2 = y[consultant_indices]\n",
    "    else:\n",
    "        y2 = y\n",
    "    \n",
    "    if 'consultant' in df1.columns:\n",
    "        df1 = df1.drop(columns='consultant')\n",
    "    df1 = df1.apply(pd.to_numeric)\n",
    "    \n",
    "    return df1, y2\n",
    "\n",
    "\n",
    "def split_data(X, y, use_random=True):\n",
    "    np.random.seed(10)\n",
    "    if use_random:\n",
    "        mask = np.random.rand(len(X)) < 0.75\n",
    "    else:\n",
    "        mask = np.arange(0, len(X)) < 0.8*len(X)\n",
    "    \n",
    "    X_train, y_train = X[mask], y[mask]\n",
    "    X_test, y_test = X[~mask], y[~mask]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def ROC_All(X1, y1, params, consultants=[], random_split=True):\n",
    "    X, y = clean_data(X1, y1, consultants)\n",
    "    X_train, y_train, X_test, y_test = split_data(X, y, random_split)\n",
    "    if params:\n",
    "        clf_xg = XGBClassifier(learning_rate=0.05, n_estimators=1000, \n",
    "                           objective='binary:logistic', seed=0, nthread=8)\n",
    "        clf_xg.set_params(**params)\n",
    "        clf_xg.fit(X_train, y_train)\n",
    "    else:\n",
    "        clf_xg = xgb_using_cv(X_train, y_train, 100)\n",
    "    fpr_all, tpr_all, y_pred_score = xgb_test(clf_xg, X_test, y_test)\n",
    "    \n",
    "    #do the fpr, tpr for different consultants\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr_all, tpr_all, label='consultant_feature')\n",
    "    ax.plot([0, 1], [0, 1])\n",
    "    \n",
    "    for c in ['Amy', 'Kristal', 'Eileen', 'Liz', 'Jen', 'Amber', 'Heather', 'Jessica']:\n",
    "        if 'consultant_'+c not in X_test.columns:\n",
    "            continue\n",
    "        indices = X_test['consultant_'+c] == 1\n",
    "        if len(y_test[indices]) == 0:\n",
    "            continue\n",
    "        fpr, tpr, _ = roc_curve(y_test[indices], y_pred_score[indices])\n",
    "        ax.plot(fpr, tpr, label=c)\n",
    "    ax.legend(loc='lower right')\n",
    "    return clf_xg, fpr_all, tpr_all, X, y, X_test, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "clf_xg_con2_tmp_tf2, fpr_all_con2_tmp_tf2, tpr_all_con2_tmp_tf2, _, _, X_test2_tmp_tf2, y_test2_tmp_tf2 = ROC_All(X2, y1, params, [], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y[y == 1])/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr_all_con2_tmp_tf, tpr_all_con2_tmp_tf, label='correct tf features')\n",
    "ax.plot(fpr_all_con2, tpr_all_con2, label='incorrect tf features')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X2.iloc[[366]]\n",
    "features = clf_xg_con2._Booster.feature_names\n",
    "test = test.apply(pd.to_numeric)\n",
    "clf_xg_con2.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf_xg_con2_tmp_tf, open('FIRST_TIME_CASE_PREDICT_CHANGE_CORRECT_TRIAGE_FEATURES.bin', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger(\"\")\n",
    "\n",
    "class XGBRecClassifier(object):\n",
    "    def __init__(self, saved_model_filepath):\n",
    "        \"\"\" \n",
    "        Initialize the class.\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        saved_model_filepath - Path to the pickle XGB model\n",
    "        \"\"\"\n",
    "        \n",
    "        self.model = pickle.load(open(saved_model_filepath, 'rb'))\n",
    "    \n",
    "    def _parse_request(self, rec):\n",
    "        rec_request_free_text2 = []\n",
    "        if 'questionnaire' not in rec:\n",
    "            return rec_request_free_text2\n",
    "        \n",
    "        user_q = rec['questionnaire']\n",
    "        for q_key, ques in user_q.items():\n",
    "            if 'answer' in ques:\n",
    "                ans = ques['answer']\n",
    "                if \"multi\" in ques['type']:\n",
    "                    for multi in ans:\n",
    "                        if \"_other\" in multi['label']:\n",
    "                            other_answer = multi['encode']\n",
    "                            if other_answer != 'n/a' and other_answer != 'none' and other_answer != 'no' and other_answer != '':\n",
    "                                rec_request_free_text2.append((q_key, multi['label'], other_answer))\n",
    "                elif \"label\" in ques:\n",
    "                    if\"_other\" in ans['label']:\n",
    "                        other_answer = ans['encode'].strip().lower()\n",
    "                        if other_answer != 'n/a' and other_answer != 'none' and other_answer != 'no' and other_answer != '':\n",
    "                            rec_request_free_text2.append((q_key, ans['label']), other_answer)\n",
    "                elif \"textarea\" in ques['type']:\n",
    "                    textarea_answer = ans['encode'].strip().lower()\n",
    "                    if textarea_answer != 'n/a' and textarea_answer != 'none' and textarea_answer != 'no' and textarea_answer != '':\n",
    "                        rec_request_free_text2.append((q_key, 'textarea', textarea_answer))\n",
    "        return rec_request_free_text2\n",
    "    \n",
    "    \n",
    "    def _has_warning(self, rec_json):\n",
    "        for card in rec_json:\n",
    "            if (card['type'] not in ['Schedule', 'Divider'] and\n",
    "                card['description'].strip() not in ['Explanation of schedule', 'Sleep Profile', 'Additional Notes']):\n",
    "\n",
    "                if card.get('warn', 0) == 1:\n",
    "                    return 1\n",
    "        return 0\n",
    "    \n",
    "    def _bad_schedule(self, rec_json):\n",
    "        for card in rec_json:\n",
    "            if card['type'] == 'Schedule':\n",
    "                for entry in card['entries']:\n",
    "                    if entry['description'].lower() != 'note':\n",
    "                        continue\n",
    "                    sentences = ['fail', 'failed', \n",
    "                                 \"total sleep hours in the schedule is less than the minimum required sleep\",\n",
    "                                 \"schedule does not follow user's reported parameters\", \"total night hours is\"]\n",
    "                    for sen in sentences:\n",
    "                        if sen in entry['time'].lower():\n",
    "                            return 1\n",
    "        return 0\n",
    "            \n",
    "    def predict(self, full_rec, rec_request, triage_features):\n",
    "        \"\"\"\n",
    "        For a given recommendation, recommendation request, and triage features\n",
    "        determine if the recommendation is EXP and the probability of it being EXP.\n",
    "        Probability ranges from 0 to 1, with 1 being 100% confident.\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        full_rec - The full recommendation including 'auto_gen', 'rec_json', 'rec_signature'\n",
    "        rec_request - The request that is associated with the full_rec\n",
    "        triage_features - Dictionary of features that shows up in triage like SA, VIP, etc.\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        isEXP - bool\n",
    "           Whether the recommendation is EXP\n",
    "        prob - float\n",
    "           Confidence of recommendation being EXP\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            X = full_rec['rec_signature']['searchArray']\n",
    "            X['other_len'] = 0\n",
    "            X['sleep_training_len'] = 0\n",
    "            rec_req_free_txt2 = self._parse_request(rec_request)\n",
    "            \n",
    "            if rec_req_free_txt2:\n",
    "                X['free_text'] = 1\n",
    "                sleep_training_note = ''\n",
    "       \n",
    "                for (qkey, label, ans) in rec_req_free_txt2:\n",
    "                    if qkey == '30173308':\n",
    "                        sleep_training_note = ans\n",
    "                \n",
    "                other_ans = []\n",
    "                for (qkey, label, ans) in rec_req_free_txt2:\n",
    "                    if '_other' in label:\n",
    "                        other_ans.append(ans)\n",
    "                X['other_len'] = len(' '.join(other_ans))\n",
    "                X['sleep_training_len'] = len(sleep_training_note)\n",
    "                      \n",
    "            if 'anything_else' in X:\n",
    "                X['anything_else_length'] = len(X['anything_else'])\n",
    "            else:\n",
    "                X['anything_else_length'] = 0\n",
    "            for k, v in triage_features.items():\n",
    "                X[k] = v\n",
    "            \n",
    "            X['bad_schedule'] = self._bad_schedule(full_rec['rec_json'])\n",
    "            X['has_warning'] = self._has_warning(full_rec['rec_json'])\n",
    "            \n",
    "            X_df = pd.DataFrame([X])\n",
    "            #FIXME: this part is a hack because ideally the feature we have matches what is in the model\n",
    "            model_columns = self.model._Booster.feature_names\n",
    "            X_df_columns = set(X_df.columns)\n",
    "            for c in model_columns:\n",
    "                if c not in X_df_columns:\n",
    "                    X_df[c] = -5\n",
    "            \n",
    "            X_df['gender_encode'] = 0\n",
    "            X_df.loc[X_df['gender'] == 'M', 'gender_encode'] = 1\n",
    "            X_df['gender'] = X_df['gender_encode']\n",
    "            X_df = X_df[model_columns]\n",
    "            \n",
    "           \n",
    "            X_df = X_df.apply(pd.to_numeric)\n",
    "            probability = self.model.predict_proba(X_df).flatten()[1] \n",
    "            if X['bad_schedule'] == 1 or X['has_warning'] == 1:\n",
    "                return False, round(probability, 2), X_df\n",
    "            else:\n",
    "                return probability > 0.5, round(probability, 2), X_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.exception(\"Error calling predict\")\n",
    "            return False, 0, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get triages that have been generated and is first time user\n",
    "#get current data that are in the queue and see which can be send out without changes\n",
    "def GetGeneratedTriages():\n",
    "    ps_connection = pool.getconn()\n",
    "    ps_cursor = ps_connection.cursor(cursor_factory = psycopg2.extras.NamedTupleCursor)\n",
    "\n",
    "    q = \"\"\"  \n",
    "        SELECT t.*, hist.id, hist.details, hist.agent, hist.time as hist_time, hist.duration, hist.notes \n",
    "        FROM triage as t RIGHT JOIN triage_history as hist on t.triage_key = hist.triage_key \n",
    "        WHERE t.status = %s AND t.age >= 4 ORDER BY t.time desc;\n",
    "        \"\"\"\n",
    "\n",
    "    ps_cursor.execute(q, ('generated',))\n",
    "\n",
    "    triage_dict = {}\n",
    "    for rec in ps_cursor:\n",
    "        t = rec._asdict()\n",
    "        key = t['triage_key']\n",
    "        if key not in triage_dict:\n",
    "            triage_dict[key] = {'uid': t['uid'],\n",
    "                                'cid': t['cid'],\n",
    "                                'age': t['age'],\n",
    "                                'sql_key': key,\n",
    "                                'status': t['status'],\n",
    "                                'due': t['due'],\n",
    "                                'time': t['time'],\n",
    "                                'turnaround_time': t['turnaround_time'],\n",
    "                                'rec_request_key': t['rec_request_key'],\n",
    "                                'request': t['request'],\n",
    "                               }\n",
    "            if t['assignee']:\n",
    "                triage_dict[key]['assignee'] = t['assignee']\n",
    "            if t['generate']:\n",
    "                triage_dict[key]['generate'] = t['generate']\n",
    "                \n",
    "            triage_dict[key]['history'] = {}\n",
    "    \n",
    "        if t['details'] == 'recs_history':\n",
    "            triage_dict[key]['recs_history'] = t['notes']\n",
    "        else:            \n",
    "            history = triage_dict[key]['history']\n",
    "            history_id = t['id']\n",
    "            history[history_id] = {'time': t['hist_time']}\n",
    "            if t['agent']:\n",
    "                history[history_id]['agent'] = t['agent']\n",
    "            if t['notes']:\n",
    "                history[history_id]['notes'] = t['notes']\n",
    "            if t['details']:\n",
    "                history[history_id]['details'] = t['details']\n",
    "            if t['duration']:\n",
    "                history[history_id]['duration'] = t['duration']\n",
    "        \n",
    "    pool.putconn(ps_connection)\n",
    "    \n",
    "    #we also need to add in recs_history\n",
    "    return triage_dict\n",
    "\n",
    "reorder_triages = GetGeneratedTriages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time_triage, req_key_to_triage, triage_to_consultant = GetFirstReq(reorder_triages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(first_time_triage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_triage_history(triage_key, isEXP, prob, agent='XGB'):\n",
    "    id_ = dn.Delorean().epoch\n",
    "    post_time = int(id_)\n",
    "    id_ = post_time\n",
    "    \n",
    "    if not isEXP:\n",
    "        return\n",
    "    notes = 'EXP={0:.2f}'.format(prob)\n",
    "    q = ('INSERT INTO triage_history (triage_key, id, details, agent, time, notes) VALUES '\n",
    "         '(%(key)s, %(id)s, %(details)s, %(agent)s, %(time)s, %(notes)s)')\n",
    "    params = {}\n",
    "    params['key'] = triage_key\n",
    "    params['id'] = id_\n",
    "    params['details'] = 'XGB Prediction'\n",
    "    params['agent'] = agent\n",
    "    params['time'] = post_time\n",
    "    params['notes'] = notes\n",
    "    print(params)\n",
    "    try:\n",
    "        ps_connection = pool.getconn()\n",
    "        ps_cursor = ps_connection.cursor(cursor_factory = psycopg2.extras.DictCursor)\n",
    "        ps_cursor.execute(q, params)\n",
    "        ps_connection.commit()\n",
    "        ps_cursor.close()\n",
    "        \n",
    "        if (ps_cursor.rowcount > 0):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        logger.exception(\"error updating triage history\")\n",
    "    finally:\n",
    "        pool.putconn(ps_connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_triage_history(triage_key, id_):\n",
    "    q = \"DELETE FROM triage_history where triage_key={} and id = '{}' and agent='XGB'\".format(triage_key, id_)\n",
    "    try:\n",
    "        ps_connection = pool.getconn()\n",
    "        ps_cursor = ps_connection.cursor(cursor_factory = psycopg2.extras.DictCursor)\n",
    "        ps_cursor.execute(q)\n",
    "        ps_connection.commit()\n",
    "        ps_cursor.close()\n",
    "        print(q)\n",
    "    except Exception as e:\n",
    "        logger.exception(\"error deleting\")\n",
    "    finally:\n",
    "        pool.putconn(ps_connection)\n",
    "        \n",
    "def del_xgb(triages):\n",
    "    num_deleted = 0\n",
    "    for triage_key, triage in triages.items():\n",
    "        skip = True\n",
    "        id_ = ''\n",
    "        for k, v in triage['history'].items():\n",
    "            if 'agent' in v and 'details' in v and v['agent'] == 'XGB' and v['details'] == 'XGB Prediction':\n",
    "                id_ = str(k)\n",
    "                skip = False\n",
    "                break\n",
    "        \n",
    "        if not skip:\n",
    "            print(triage_key, id_, triage['cid'])\n",
    "            del_triage_history(triage_key, id_)\n",
    "            num_deleted += 1\n",
    "        \n",
    "xgb_triages = GetGeneratedTriages()\n",
    "del_xgb(xgb_triages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = X_test2_all.copy()\n",
    "xgbclassifier = XGBRecClassifier(\"FIRST_TIME_CASE_PREDICT_CHANGE_CORRECT_TRIAGE_FEATURES.bin\")\n",
    "model = xgbclassifier.model\n",
    "model_columns = xgbclassifier.model._Booster.feature_names\n",
    "X_df_columns = set(X_df.columns)\n",
    "for c in model_columns:\n",
    "    if c not in X_df_columns:\n",
    "        print(c)\n",
    "        X_df[c] = -5\n",
    "            \n",
    "X_df['gender_encode'] = 0\n",
    "X_df.loc[X_df['gender'] == 'M', 'gender_encode'] = 1\n",
    "X_df['gender'] = X_df['gender_encode']\n",
    "X_df = X_df[model_columns]\n",
    "            \n",
    "X_df = X_df.apply(pd.to_numeric)\n",
    "probability = xgbclassifier.model.predict_proba(X_df)[:, 1] \n",
    "\n",
    "fpr, tpr, thresh = roc_curve(y_test2_all, probability)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr, label='old model')\n",
    "ax.plot(fpr_all_con2_all, tpr_all_con2_all, label='new model')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "xgbclassifier = XGBRecClassifier(\"FIRST_TIME_CASE_PREDICT_CHANGE_CORRECT_TRIAGE_FEATURES.bin\")\n",
    "new_triages = GetGeneratedTriages()\n",
    "first_time_triage, req_key_to_triage, triage_to_consultant = GetFirstReq(new_triages)\n",
    "\n",
    "num = 0\n",
    "for sql_key in first_time_triage:\n",
    "    triage = new_triages[sql_key]\n",
    "    skip = False\n",
    "    for k, v in triage['history'].items():\n",
    "        if 'agent' in v and v['agent'] == 'XGB':\n",
    "            skip = True\n",
    "            break\n",
    "#     if skip:\n",
    "#         continue\n",
    "\n",
    "    if 'cid' not in triage or triage['cid'] == None: \n",
    "        continue\n",
    "    \n",
    "    if not triage['cid'].startswith('yQPQ'):\n",
    "        continue\n",
    "        \n",
    "    rec_request = db.reference('rec_requests/{uid}/{rec_req_key}'.format(uid=triage['uid'], \n",
    "                                                                         rec_req_key=triage['rec_request_key']))\n",
    "    rec_request = rec_request.get()\n",
    "    full_recs = db.reference('draft_recommendations/{cid}'.format(cid=triage['cid'])).get()\n",
    "    if not full_recs:\n",
    "        continue\n",
    "    num_rec = 0\n",
    "    try:\n",
    "        for recdate, rec in full_recs.items():\n",
    "            num_rec += 1\n",
    "    except Exception as e:\n",
    "        print(triage, triage['cid'])\n",
    "        continue\n",
    "    \n",
    "    if num_rec > 1:\n",
    "        logger.warning(\"not first time user\")\n",
    "        continue\n",
    "    if num_rec == 1:\n",
    "        #perform classification\n",
    "        _, triage_features = case_classifier(triage)\n",
    "        isEXP, prob, X_df = xgbclassifier.predict(rec, rec_request, triage_features)\n",
    "        if isEXP:\n",
    "            print(isEXP, prob, triage, triage_features)\n",
    "            time.sleep(2)\n",
    "            #update_triage_history(triage['sql_key'], isEXP, prob)\n",
    "            num += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from eli5 import show_prediction\n",
    "show_prediction(xgbclassifier.model, X_df, feature_names=X_df.columns.values, show_feature_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
